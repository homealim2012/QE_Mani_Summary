19910418000000000	FT  18 APR 91 / Technology: Cat-scan takes on a new life. In 1971 EMI scientist Godfrey Hounsfield's brain-scanner gave neuro-surgeons their first glimpses inside a living brain without breaking the skull. Computer-assisted tomography (Cat) was the invention for which Hounsfield shared the Nobel prize for medicine in 1979. In the 1980s Cat-scanning using X-rays was displaced in medical diagnosis by the safer method of magnetic resonance imaging which uses no radiation. But Cat-scanning continued to be developed as a non-destructive test process for peering deep inside complex assemblies, especially when they are encased in metal. The essence of Cat-scanning is to take several X-ray images of the object from different angles, and process the information on image density by computer. In this way a 3-D simulation is created which can reveal, for example, the location of a brain tumour. Lawrence Livermore National Laboratory in California, one of the US Department of Energy's nuclear weapon design centres, has developed novel scanners for examining specific situations. With explosives, for example, the technique can find cracks or voids that would impair the efficiency, can verify its density and ensure that the substance had been properly mixed. One of several different Cat-scanners designed at Lawrence Livermore examines the insides of nuclear weapons. Another collaboration is with the University of California at Davis. Experiments are under way to determine what substances a Cat-scan might reveal in soil samples. So far, tests have shown that the scan can detect cotton seed and locate voids as small as 300 microns across. Another topical challenge is the rapid inspection of large drums of radioactive waste before their long-term disposal, to provide assurance on their radioactivity level. Much of the waste from US sources is incorrectly identified at present, because the customary means of characterisation cannot certify that they can be classed as low-level or non-radioactive.
19920325000000000	FT  25 MAR 92 / Champion of liberty and law: The work of the late Friedrich von Hayek. Many would say that if Mrs Margaret Thatcher is a conviction politician, the convictions are those of Friedrich von Hayek, who died on Monday at the age of 92. Yet the conclusion would be unfair to both. Although the former UK prime minister was a great admirer of the late economic philosopher, Hayek mainly provided articulation and confirmation of convictions Mrs Thatcher had already reached. The admiration was reciprocated, yet there was much in his writings that some would see to be at variance with Thatcherite practice. Friedrich August von Hayek was born in Vienna on May 8 1899. His father was a professor while the imperial city was enjoying its celebrated sunset. Brahms had only recently died, and Freud had yet to publish his major works. Hayek's own career began in the civil service, and after holding academic posts in Vienna he came to the Lon-don School of Economics in 1931. Recalling his arrival, Lionel Robbins subsequently wrote: 'I can still see the door of my room opening to admit the tall, powerful, reserved figure which announced itself quietly and firmly as 'Hayek' '. His lectures were so successful that the school's director, William Beveridge, suggested that he remain as Tooke Professor, a post he held until 1950. Hayek brought a whole host of cosmopolitan contacts to the LSE. He was, for instance, instrumental in the appointment of Sir Karl Popper, the philosopher and author of The Open Society. Although Hayek's later career took him first to Chicago and then back to Austria and Germany (his last years were spent in Freiburg in Breisgau), he retained his British nationality (acquired in 1938), and he remained a close observer of the British scene. He was a joint winner of the Nobel Prize for economics in 1974. He was twice married; he leaves a widow, Helene, and a son and daughter. Hayek's fortunes teach us a great deal about intellectual fashions. During the 1930s he was mainly known for technical economic studies, which were at the time overshadowed by the new Keynesian theories on unemployment and economic policy. One conclusion from that period, recently disinterred, is that market institutions could not just be grafted on to state socialism, as mainstream economists long believed was possible. Hayek's greatest intellectual regret for those years is that he never wrote a full-scale critique of Keynes's The General Theory. He had previously written a long review of the first volume of Keynes's earlier Treatise on Money - only to be told by Keynes that the latter had changed his views. This experience led Hayek to suppose that The General Theory was just another 'tract for the times'. In the 1940s Hayek became a hate figure to those on the political left because of his onslaught on centralised economic planning and his insistence on the links between political and economic freedom in his best-selling Road to Serfdom: the book is said to have influenced Winston Churchill's controversial 1945 election broadcast about the threat of a 'Gestapo' under socialism. It is less well known that Keynes sent Hayek a letter expressing his deeply felt agreement with at least some of the argument. Hayek was not a charismatic public figure. His brief post-war notoriety was followed by decades of neglect, during which his most important constructive works on the foundations of a free society were written. Indeed, I was first attracted to his writings by his concern, voiced in The Constitution of Liberty (1960), 'for that condition of man in which coercion of some by others is reduced as much as possible'. Finally, following his Nobel prize in 1974, he emerged as a cult figure of the radical right - which did neither side too much good. For there was far more to Hayek than the demolition of socialism and the standard case for free markets. In presenting him as a revered thinker with a complete system, his followers may have made his work neater, simpler and less interesting than it really was. Although Hayek was far too shrewd to overrate the Nobel award, for one reason or another the years following it witnessed a rejuvenation. Among political theorists and sociologists critical of the new right, he was studied more seriously than the more fashionable economic technicians. But he took this adulation with a large pinch of salt and was no more a Hayekian than Keynes was a Keynesian. Hayek was unfashionable in the 1950s and 60s as much for academic as for political reasons. At a time when most go-ahead economists were raring to equip themselves with forecasting models and computer print-outs, Hayek - in contrast to Milton Friedman - seemed an armchair thinker, preoccupied with ideas such as the limitations of human knowledge and the problems that economists would have if they tried to ape the natural scientist. But in the longer haul the contrast did not necessarily tell against Hayek. A disadvantage of recent methodological orthodoxy is that many economists have acquired a vested interest in the existence of stable, discoverable numerical relationships between phenomena such as income and consumption, or short-run changes in the money supply and the price level. Hayek warned that one could not guarantee the successful discovery of such relationships, but that scientific method could still be applied to predict certain general features of interacting systems - as it is, for instance, in biology and linguistics. His insistence that, while inflation is a monetary phenomenon, there is no such thing as 'the quantity of money', and no sharp boundary between money and other financial assets, has stood the test of time. The experience of the British government, which has changed its view of monetary targets so much and to so little avail, was much less puzzling to a Hayekian than to a true monetarist believer. So, too, was the high unemployment cost of reducing inflation, which Hayek insisted was inevitable while labour markets were dominated by the collective bargaining mentality. Hayek's defence of the market system was subtly different from that of many economists. Whereas mainstream economists have been preoccupied with the optimal allocation of resources in given conditions, Hayek was concerned with the effect of the market system on the evolution and stability of society. He was interested in markets as examples of human institutions, like language or law, which have evolved 'as a result of human action, but not of human intention'. He insisted that wants, techniques and resources are not given, but are constantly changing - in part because of the activities of entrepreneurs who open up possibilities which people did not know existed before. (The dynamic and entrepreneurial aspect was also emphasised by another economist of Austrian origin, Joseph Schumpeter, thus providing a so-called 'Austrian' critique of mainstream neo-classical economics, which overlaps with the objections of 'radical' political economists.) According to Hayek, a market system is a discovery technique. No computer can predict the emergence of new knowledge, original ideas, or innovations - and people's reactions to them. His scepticism about the use of econometric relationships was based on a wider epistemological view. For he insisted that the most important kind of knowledge was not of propositions or theories, but of practical skills and dispositions governed by rules which we may imperfectly discover afterwards, but not formulate in advance. For Hayek the cardinal sin of our times was something known by the ungainly label of 'constructivism'. This was akin to what Michael Oakeshott called 'rationalism', and is the error of believing that any order we find in society has been put there by a designing mind - and can be, accordingly, redesigned from scratch. Hayek was very far from believing the conventional bourgeois pieties. He never imagined that there was anything just in market rewards. These depended on an unpredictable mixture of effort, ability and luck. Quite apart from the adverse economic consequences, it was not desirable even to try to reward merit through public policy, which would involve some authority deciding how much pain and effort a task had cost and how much of a person's achievement was due to outside circumstances. But, characteristically, Hayek spoiled a splendid and heretical contribution by insisting that any public policy towards the distribution of income and property (beyond the provision of a very basic social-security minimum) involved political assessment of merit and was thus incompatible with a free society and the rule of law. However, Hayek did not in fact provide any easily recognisable criteria for identifying state interventions of the harmful type. The free-market arguments in The Road To Serfdom were based on the incompatibility of central planning with personal liberty. In subsequent years Hayek approached the issue indirectly. He argued, especially in The Constitution Of Liberty, that the main condition for a free society is what he called 'the rule of law'. By that he meant a presumption in favour of general rules and against discretionary power. He attempted to derive from this conception not only the fundamental political and legal basis, but also the economic policies, of a free society. Many writers of the most diverse political persuasion accepted that general rules were an important protection - perhaps the most important single protection - for freedom. But Hayek was criticised for suggesting that general laws were a sufficient condition for a free society. Many policies involving a high degree of coercion can be imposed by general rules - for example, a ban on the teaching of evolution or on any literature or music which flouts the principles of Marxist-Leninism. There is no one philosopher's stone for minimising coercion in society. Hayek's concern to restore a government of laws rather than men can be seen from his later writings which warned of the degeneration of democracy into a struggle for spoils among competing groups. He saw the source of interest-group domination in what he called 'majoritarian' or unlimited democracy. This is the belief that a government elected by a majority of voters (usually a plurality) should be able to enact what it likes without any check - a system which Lord Hailsham has termed an elective dictatorship. Some of Hayek's own constitutional proposals struck even his admirers as far-fetched. But their underlying aim was important. It was to recover an older idea of a state, which has no purposes of its own, but provides a framework of rules and arrangements under which people can pursue their own individual aims without getting in each other's way. This ideal - which is a long way removed from the practice of any modern government, even of the radical right - has been labelled by Oakeshott as a 'civil association', as opposed to the more usual idea of the state as an 'enterprise association' with its own aims and purposes. The close similarity of the later work of both Hayek and Oakeshott, pursued in relative isolation, is a theme which deserves a study of its own. There were great ultimate differences between Hayek and others who shared a similar outlook. Unlike most classical liberals, Hayek's espousal of liberty turned out to be based neither on ultimate judgments, nor on considerations of welfare, utility or happiness. He did not even accept the methodological individualism of most mainstream economists. For him, the key to institutions was natural selection among competing traditions. This evolutionary approach remained in the background in the classic politico-economic works of his middle period. But its roots went back to his student days when he was as concerned with philosophy and biology as with economics. The evolutionary outlook landed Hayek with problems. For it made it difficult to criticise any social order (eg Stalinist Russia) which was not visibly dying out. Hayek's refuge in evolution was not just idiosyncratic, but can be seen as a response to the failure of attempts to build deductive systems of morality which will apply to specific cases. His own inability to resolve the ultimate conundrums of human conduct should not obscure the range of his achievements. Hayek's writings have asserted the case for general rules over discretionary authority. They have exposed the misleading identification of a liberal democracy with the divine right of temporary majorities. They have demonstrated the connection between economic and personal freedoms. They have shown that the domination of both the political and economic market-place by interest group struggles is a source of evil; and they have explained why pecuniary rewards neither can nor should reflect merit. In all these matters Hayek - like Keynes or Friedman or the American philosopher John Rawls or other such seminal figures - is best treated as an intellectual agent provocateur rather than a pundit with all the answers.
19920324000000000	FT  24 MAR 92 / Election 1992: Small science - Ballot Box. The group of pro-Labour scientists who wrote to The Times yesterday were stretching a point. 'Between 1974 and 1979,' they said, 'British scientists won six Nobel prizes. In 1980-85 the number dropped to four, and for 1986-91 there was just one British laureate.' About the long-term trend, they may well be right, but there is a time lag in these matters and it is surely pushing it a bit to claim the number of prizes between 1974-79 as a triumph for the Labour government of that period. Most Nobel prizes are based on research done five to 20 years previously, though the interval between a discovery and its recognition by the Nobel committee varies enormously. Cesar Milstein of the Laboratory of Molecular Biology in Cambridge discovered monoclonal antibodies - a key development in molecular biology - in 1976 and won a Nobel Prize in 1984, which was fast by Nobel standards. On the other hand, Peyton Rous discovered in 1911 that viruses can cause cancer. He won the prize in 1966. Perhaps the scientists who did their best work in the Thatcher period will get their reward by the millennium.
19920910000000000	FT  10 SEP 92 / Book Review: Mind the gaps. BRIGHT AIR, BRILLIANT FIRE: On the Matter of the Mind By Professor Gerald Edelman Allen Lane, Pounds 20, 280 pages Putting the mind back into nature' is the slogan of Professor Gerald Edelman's crusade. One of the world's leading brain scientists, and winner of a Nobel prize in 1972 for his work in immunology, he has turned to the philosophy of science to address what he calls a 'series of crises' in the science of the brain and nervous system. The problem he sets himself is to explain, in biological terms, how people came to have minds. By 'minds' he means not brains, but self-consciousness - awareness of ourselves. It is a question that has occupied philosophers for centuries. He makes grand claims: 'We are at the beginning of the neuroscientific revolution. At its end, we shall know how the mind works, what governs our nature, and how we know the world.' He argues convincingly against recent theories that the brain is built like a computer. Neuroscientists who use the model of a circuitboard to explain the activity of 'the most complicated object in the universe' will find accurate predictions of its behaviour elusive, he says. Far from being 'hard-wired' like a computer, the connections between the 10bn neurons in the cortex of the brain are constantly changing. New paths are forged and strengthened by experience and patterns of behaviour. Edelman describes this adaptation of the maps inside the human brain as 'neural Darwinism'. Edelman has the gift of explaining difficult scientific concepts clearly and quickly. A well known advocate of popularising science, he begins his public lectures by reciting Keats and Emily Dickinson, and scatters his text with pictures of startled frogs and mutant flies, quotes from Woody Allen and anecdotes from Manhattan life. But his book fails to make the bridge between biology and soul in the way he intends. And while his populist style is entertaining, it depends on metaphors which promise much but are eventually insubstantial or inexact when he departs from neuroscience and comes to the crux of his argument. For a start, as one of his rivals has commented, the parallel he draws with Darwinian evolution is unconvincing. Darwin argued that species evolved by mutation and the survivors were 'selected' by fierce competition. Neural structures, however, do not reproduce or compete in the same way as animals. To say that they do is almost to start to ascribe consciousness to their parts. Similarly, an early chapter on the spectacular successes of genetics in 'reading' the characteristics of an organism from a strand of DNA is not woven into his case that it may eventually be possible to 'read' thought and morality from the structures of the brain. The awkward metaphors multiply as the book moves from science to philosophy. Edelman briefly quotes and then dismisses many philosophers who have grappled with the problem of the nature of consciousness and the self, notably Descartes and Kant. Past writers could not have known what we now know about the structure of the brain, he says, with the patronising air of the chief detective summing up at the end of the thriller. But he discusses few of the philosophers who would have dismissed his quest. Notably, he gives little space to Wittgenstein and his followers, who would have argued that Edelman's speculation about whether a lobster has self-consciousness was meaningless. Some philosophers would argue that a lobster shows none of the signs of what we mean by self-consciousness. Only by distorting the way the term is normally used would one be led like Edelman into examination of its nervous system to see whether it is conscious. Edelman's bending of ordinary language increases in later chapters. In one definition he says: 'To clarify the issue, let us agree that . . . memory is the ability to repeat a performance'. That is a peculiarly limited version of what we normally mean by memory, but it allows Edelman to build a robot, called Darwin III, which he argues shows 'memory'. Edelman's theories will comfort those who feel that science leaves no place for the soul, and that scientists cannot tell jokes and do not read Keats. His ideas also deserve attention because of his conclusion that 'every psychiatric illness has a biological cause'. He makes no secret of his dream of finding the neural answer to many types of mental distress, and he and his fellow-thinkers are likely to attract thousands of dollars of research money in pursuit of that goal. But, by the end, his book does science few favours. Darwin's original theory of evolution may be a poor model for brain development, but it is a good one for the growth of scientific knowledge, which emerges gradually as competing hypotheses are tested and eliminated. Darwin's own theories have, more or less, survived that demanding test in the past 130 years. So probably will Edelman's contribution to immunology and to brain science. His excursions into the philosophy of mind, however, show fewer of the characteristics of fitness to survive.
19921015000000000	FT  15 OCT 92 / Atom-smasher work wins Nobel physics prize. THE WINNERS of the Nobel physics and chemistry prizes, announced in Stockholm yesterday, made discoveries which helped to uncover some of the most fundamental processes in science. The physics laureate, Professor Georges Charpak of France, invented the electronic detector which is now used in all the world's 'atom smashers' to trace the sub-atomic particles thrown off by high-energy collisions. His multi-wire proportional chamber makes it possible to collect data 1,000 times faster than the old photographic detection methods, the Swedish Academy of Sciences said in its citation. Prof Charpak, 68, works at Cern, the European particle physics laboratory near Geneva. His detector - invented in the 1960s - was used by colleagues from Cern who won the 1984 Nobel physics prize for discovering some of the innermost structure of matter. Now, simpler versions of the detector are being developed for more practical applications, for example in detecting medical X-rays. Professor Rudolph Marcus of the US won this year's chemistry prize for 'his theory for what is perhaps the simplest chemical elementary process: the transfer of an electron between molecules,' the academy said. Prof Marcus, 69, works at the California Institute of Technology in Pasadena. His theory, developed during the 1950s and 60s, has made useful predictions in many areas of chemistry, including the way plants fix light energy in photosynthesis and the conduction of electricity in plastics. Some predictions conflicted with what chemists had previously expected. These were not finally confirmed by experiment until the late 1980s. Prof Charpak is France's ninth physics prize winner and Prof Marcus is the 39th American to win the chemistry prize. Each prize is worth about Dollars 1.2m this year.
19921014000000000	FT  14 OCT 92 / Nobel prize winner extended the realm of economic theory. MR GARY BECKER, named yesterday as this year's winner of the Nobel prize for economics, is proof that economists have more to offer than dubious forecasts, indecipherable equations and contradictory conclusions about the behaviour of money and markets. Revered among his fellow professionals for his seminal work on the economics of discrimination and human capital theory, the 61-year-old professor at the University of Chicago has spent the past 40 years extending the discipline of economics far beyond the world of international trade and finance. Mr Becker was the first to show that racial discrimination was economically costly and relied upon the existence of monopoly power. Only companies with market power could afford to ignore qualified candidates or refuse paying customers because of their colour or religion. So encouraging competition is the best way to end discrimination. He also investigated how we punish criminals and why prison sentences for unarmed robbery are much lower than those for armed robbery. Mr Becker argued that the criminal balanced the rewards from crime against the probability and cost of capture, so not all crimes should receive too tough a sentence. Attaching a life sentence to unarmed robbery would reduce the number of thefts, but it might also increase the number of murders once the marginal disincentive for petty thieves to use guns was removed. Mr Becker has also examined the loosening of US divorce laws. Contrary to conventional wisdom, allowing one party to file a divorce suit rather than requiring mutual consent has not led to more divorces in states which have taken this route. However, as Mr Becker predicted, the size of financial settlements has fallen sharply now that there is no need for an agreement to the divorce. Mr Lawrence Summers, an economics professor at Harvard university and currently chief economist at the World Bank, says that policymakers should have predicted this result. 'One of the most important unintended consequences of the divorce revolution in the US - the impoverishment of hundreds and thousands of children - would have been apparent if they had studied Becker's seminal approach.'
19930130000000000	FT  30 JAN 93 / Books: Just a bundle of energy - AC Grayling goes in search of the grail of fundamental physics. DREAMS OF A FINAL THEORY by Steven Weinberg Hutchinson Radius Pounds 16.99, 260 pages SCIENCE has advanced so dramatically in the 20th century that its practitioners often feel, says Steven Weinberg, like 'Siegfried after he tasted the dragon's blood, when he found to his surprise that he could understand the language of birds'. First, Einstein's relativity theories changed our concepts of space, time and gravity. Later, quantum mechanics dissolved the world of material particles into wave functions and probabilities. And then the marriage of relativity and quantum theory produced a surreal world of hidden symmetries in which the concept of matter no longer figures. This is heady progress. Part of Weinberg's aim in his stimulating book is to tell how it happened and what it means. He is well-equipped to do so; in 1979 he won the Nobel Prize for physics, and later wrote a famous popular account of the origins of the universe, The First Three Minutes. But Weinberg has a second and for his own purposes more important aim, which is to argue in support of a dramatic 'Big Science' project aimed at exploring hitherto unreachable levels of physical reality. In the last two decades, Weinberg says, particle physicists have been frustrated. The reason is that theory has outstripped experimental capacity. Theoreticians have leaped ahead in conceptualising the deep structure of the universe; but to test their ideas new laboratories are needed, unprecedentedly large and expensive. This book states the case for building them. It is a topic close to Weinberg's heart. He is head of an Dollars 8bn project in Texas to construct a Superconducting Super Collider (SSC), a 53-mile-long oval tunnel in which protons can be smashed together at energy levels far greater than those now experimentally possible. The results promise a dramatic increase in scientific understanding. In testifying to Congressional funding committees on behalf of the SSC, Weinberg found that he had to explain the recent history of particle physics, its present deadlock, and the discoveries that an SSC promises. He also found himself defending fundamental physics against its critics, among them other scientists wishing to promote their own research in the fierce competition for funds. An obvious format for a non-specialist statement of Weinberg's case is a book; and here it is - highly literate, comprehensive, challenging, a survey of an exciting and extraordinary field of enquiry by one of its leading figures. Weinberg's task is to describe the current 'standard model' of elementary particles and forces, and to explain why it is now at an impasse. The model results from marrying relativity and quantum mechanics, which are mutually incompatible in all but a very few interpretations. The standard model is the best of these few. In older theories, atoms were conceived as miniature planetary systems with electrons orbiting a nucleus. The new model argues that there are no particles as such, only bundles of energy in various fields. Fields are modifications of space, and there is one for each type of particle. Electrons are energy bundles or 'quanta' in electron fields, photons are quanta in electromagnetic fields. The nuclear particles are themselves compounds of more elementary quanta, 'quarks', each with their own fields. These phenomena are described by field equations, and their interactions - the strong and weak nuclear forces, the electromagnetic force, and gravity - are governed by the general principles of quantum mechanics and relativity. This model has proved highly successful in its predictive and explanatory power. But it is full of problems, which theoreticians have been trying to understand and which SSC-type experiments might resolve. The chief is that, although the standard model offers some success in unifying the electromagnetic and weak nuclear forces, it does not unify them with the strong nuclear forces. Still worse, it has no way of describing gravitation in terms of quantum field theory. The aim of deriving a unified theory for all nature's forces is therefore at a stand. Such a theory is the grail of fundamental physics, and would, in Weinberg's view, constitute the "Final Theory' about physical reality. Theoreticians offer proposals, like 'superstring theory', to overcome the standard model's difficulties. But only SSC-type experiment can turn such guesses into progress. Weinberg promotes the SSC as a key towards discovering the final truth about the universe. This involves him in two controversial commitments. First, he is a realist about the standard model; he believes that field theory describes the world as it really is. And therefore, secondly, he is a reductionist about particle physics; he believes that all other sciences rest on it, and 'with enough computer power and time' can be explained by it. These beliefs involve him in quarrels with fellow-scientists unpersuaded by reductionism, and with philosophers unpersuaded by realism. Many biologists count among anti-reductionists. They see living organisms as having 'emergent' properties inexplicable on the basis of microstructure alone. Emergent properties are those which complex systems have but their parts lack; consciousness, and life itself, are examples - neither seem inferrable from an organism's underlying physics. Even some of Weinberg 's fellow-physicists, those working on condensed matter and low temperature phenomena, are unpersuaded that particle physics answers their questions. These issues are profoundly important, and not just because billions of research dollars turn on them. Weinberg is right to oppose those philosophers whose scientifically illiterate relativism leads them to think that science is merely one among many ideologies, and - according to some - a 'sexist, racist and imperialist' one at that. But he misunderstands Positivism, which he defines as the claim that science should avoid talk of unobservable entities and forces. Positivists indeed allow such talk, but treat it as purely instrumental in helping us to construct useful theories. Weinberg believes that one can deduce a theory's truth from its utility, but Positivists deny this; Ptolemy's geocentric astronomy worked for navigation and prediction of eclipses, they point out, but we do not think it true. Weinberg's controversial claims are stimulating and the whole issue of fundamental physics, now at a crucial point in its history, is immensely important. The question is: should we invest further huge sums in attempts to understand the universe, with so many other demands on our purses? Weinberg has written an important, and an exhilarating, book in urging the affirmative answer.
19931021000000000	FT  21 OCT 93 / Technology: Domain of the genes / A look at a breakthrough in biotechnology. Richard Roberts and Phillip Sharp helped take the nonsense out of gene research - literally. Without their work, for which they have just jointly been awarded the Nobel prize in medicine, much of today's biotechnological developments would not have been possible. The award highlighted the importance of biotechnology in medical research by giving formal recognition to a discovery in gene structure that has yielded new product developments in the biotechnology sector and promises to lead to many more. The achievement of British-born Roberts and Sharp, an American, was to overturn the idea that genes were arranged on DNA strands in a continuous chain. Instead, they found that genes have distinct 'domains' or gene sequences, separated by what have been called nonsense DNA or introns. They made the discovery simultaneously but independently in 1977 by using electron microscopes. It is credited with speeding up the biotechnology revolution and paving the way for gene therapy, a nascent field in which genes are used as drugs. Genes are arranged along strands of DNA, which contain the blueprints for the creation of life. To reproduce itself, DNA unzips into RNA messenger strands, carbon copies of the DNA. The RNA then invades protein molecules and imprints them with the genetic codes for development. The laureates' breakthrough showed that the messenger RNA edits out the introns between the gene sequences to form a clear genetic code that can be read by proteins, the building blocks of life. The discovery was applied immediately to the fabrication of certain hormones, for instance the human growth hormone used to treat dwarfism. 'It became clear after this discovery that if you were going to express a gene for a hormone, you'd first have to remove the nonsense sequences,' says Sharp. The discovery also yielded clues for research into cancer and certain hereditary diseases which occur from mistakes during the DNA copying and editing process. 'After the study, scientists were able to study genes in the cancerous or mutant state and compare it to the normal state,' says Roberts, a researcher at New England Biolabs. 'Before the discovery, we did not know what the normal state looked like.' Sharp and Roberts did their work in 1977, but some of the possible applications of the discovery are only now being fully explored. 'It's not just that we realised genes were divided into sequences,' says Joseph Davie, vice-president of research at Biogen, the biotechnology group. 'We realised they had separate domains for a reason, which was that they had different functions. One of the important things to come out of this is that we realised we did not have to create copies of molecules just as they were found in nature. We could split up their functions and re-arrange them to create our own, new molecules by combining part of one gene and part of another.' This technology is still in its early stages, but some biotechnology groups say they are having success. Seattle-based Immunex is developing a bone marrow stimulant which brings two gene domains together in a single molecule. And Biogen says it is also working with 'designer molecules' to target cancer, inflammatory, immunological and cardiovascular diseases. 'One area we've had success in,' says Sharp, one of the founders of Biogen and now a professor at the Massachusetts Institute of Technology, 'is in making new antibodies by combining mouse antibodies with human antibodies. This allows some of the mouse antibodies to be used by humans.' Since 1977, scientists have been advancing their knowledge of how genes work. 'The reason it's taken so long since the original discovery for companies to start getting into mixing is because first we had to know what individual gene domains actually do,' says Davie. 'Now we can become more sophisticated in mixing them up.' New sophistication in gene splicing has improved research methods. 'The 'gene knockout' technique, by which you eliminate certain genes in mice, is now used widely to create mutations which are then used in research,' says Laurence Lasky, staff scientist at Genentech. 'That would not have been possible without the Nobel work.' The discovery was also fundamental to advances in the complex field of gene therapy. 'Unless you understand how a gene is expressed, there is no hope for gene therapy,' says Dr Sharp. According to Hubert Shoemaker, chairman of Centocor, the work was also important because it stressed that when the gene message gets re-processed, it may get mixed up. 'We need to take into account the stability of the genes we create in the field,' he explains. Sharp and Roberts stress that their work was just one step in a revolution of new ideas which have exploded over the last two decades. Several important discoveries followed on the heels of the Nobel laureates' initial work. After the notion of gene domains was established, for instance, scientists began to consider the possibility of using RNA as an enzyme. 'We began to see that RNA molecules have a function besides the transferring of information,' says Shoemaker. 'They can also function as enzymes and we may see a whole new series of drugs based on RNA as enzymes.' Researchers also began to consider using adhesive RNA strands as inhibitors. 'We have now adopted the concept that there is a single domain on the gene which is responsible for binding,' says Lasky. Normally, we think of peptides and other substances as binders, but RNA portions may also be used. If they bind to a specific site, the activity of that molecule may be inhibited. This could be used as a drug for a number of diseases including Aids.' Another key development is the discovery that introns serve as moderators in the expression of the gene sequence. 'By including introns in the expression of a system, we can get a much more effective protein,' says Patricia Tekamp-Olson, director of research at Chiron. 'It's very likely that they will be increasingly used as enhancers for recombinant proteins. Another theory is that they may provide information which makes the gene tissue specific. For instance, we may be able to use introns to target specific tissues within the body while ignoring others. That would be a key advance.'
19931013000000000	FT  13 OCT 93 / Observer: Early bird awaits worm. If this year's Nobel prize winners were to seek any tips from their immediate predecessors, the advice would surely be to press for the lolly quick. Last year's laureates were spectacular victims of Europe's autumn currency crisis. Their awards, each worth SKr6.5m, were announced in October, but had shrunk by about 15 per cent in dollar terms by the time they were paid in December, following the November flotation of the Swedish krona. The latest recipients have been told that their prizes, worth SKr6.7m, will again be paid in December. Now worth a third less against the greenback than before the flotation, the krona is still tending to slither southwards. At least yesterday's winners, Robert Fogel of Chicago University and Douglass North of Washington University, should understand, for they are both economic historians. They are also upholding a tradition, for American economists have now swept the board for four years running, with the University of Chicago featuring each time. Self-effacing panel chairman Assar Lindbeck, the Stockholm University economist who earlier this year led a benchmark study on the precarious state of the Swedish economy, even went on to admit that the American dominance of the subject extended into new economic history. The last non-American to win was Norwegian econometrist Trygve Haavelmo, whose reaction to the announcement in 1989 was to mutter his disapproval of prizes before disconnecting his telephone and retreating to his country cottage. Contrast Fogel, who was called by Stockholm at 5 am Chicago time with the news of his honour. Already in his office, he whipped up the telephone on the first ring.
19931013000000000	FT  13 OCT 93 / Economic historians win Nobel. THE Nobel prize for economics was yesterday awarded to Robert Fogel of the University of Chicago and Douglass North of Washington University in St Louis for pioneering work on the causes of economic and institutional change. The Nobel committee's decision to break with tradition and award the prize for work in economic history, rather than economics proper, reflects the growing importance economists attach to the role of social institutions in providing a framework for economic growth. Professors Fogel and North are widely credited with revolutionising economic history as an academic discipline by applying rigorous statistical techniques and theories. The approach is known as 'cliometrics' or 'the new economic history'. 'It's a tremendous decision,' said Prof Roderick Floud, provost of London Guildhall University, who has collaborated with Prof Fogel for the past 10-15 years. He said their emphasis on quantitative techniques had transformed economic history and stimulated greater numeracy in other branches of history. Prof North, 72, has cast doubt on many traditional explanations of economic growth, arguing that factors such as technical change and innovations are less important than previously claimed. He puts more stress on legal and social institutions, such as property rights, that create the conditions in which market economies can flourish. His work is of particular relevance to former communist countries where the lack of capitalist institutions is widely seen as one of the main obstacles to development. Prof North recently advised the Czech Republic on privatisation. He previously acted as a consultant in Russia, Argentina and Peru. 'He is adamant that you cannot just leave development to markets,' said Prof John Nye, a colleague of Prof North at Washington University. 'He is trying to push back the boundaries of economics by getting economists to focus on institutions as well as exchange and allocation.' Prof North has also used the modern economic theory of transactions costs to throw new light on feudal and medieval economies. He concluded these forms of economic organisation were efficient given existing institutional constraints. Prof Fogel, 67, pioneered the application of rigorous statistical techniques in economic history, in the process turning conventional wisdom on its head. Historians, for example, have long argued that the development of railways played a crucial role in US economic development. Prof Fogel rejected this claim, arguing that had railways never existed, US gross national product would have been only 3 per cent lower. He argued that in the absence of railways substitute forms of transport such as roads and canals would have played a more important role. This type of 'counterfactual' analysis, familiar to economists, was new to economic historians. In a study that provoked bitter criticism, Prof Fogel rejected the conventional wisdom that American slavery was an inefficient, unprofitable economic system. His careful statistical analysis indicated that slavery was economically viable and would have persisted but for political opposition. He did not, however, attempt to justify slavery, arguing that it was morally unacceptable. More recently Prof Fogel has helped to develop a new branch of economic history that uses biomedical data on human height, weight, food intake and morbidity as a gauge of changes in economic welfare.
19931012000000000	FT  12 OCT 93 / World News in Brief: Briton shares Nobel Prize for Medicine. British-born scientist Richard Roberts and US colleague Phillip Sharp shared the SKr6.7m (Pounds 550,000) Nobel Prize for Medicine for discovering split genes and advancing research on cancer and hereditary diseases. They independently discovered that genes could be present in DNA not just as one but as several separated segments. This led to the discovery of splicing - the assembly of information from the segments.
19940312000000000	FT  12 MAR 94 / Private View: More Big Bang for our bucks - Christian Tyler meets the man responsible for Europe's planned proton-smasher. What is it worth to you if they discover the Higgs boson? It is not an idle question, for this summer ministers and their advisers from 19 European countries are likely to tell the scientists of Cern, the particle physics laboratory outside Geneva, that they can have Dollars 1.5bn (Pounds 1bn) of taxpayers' money to build a big proton-smasher inside their 27km circular tunnel. Few of us taxpayers will get a chance to say what we think about this latest stage in the hunt for particles that might illuminate the dawn of time. So, calculating my own contribution at about Pounds 1 a year - say a fiver for the family - I flew to Geneva to ask the head boson-hunter what the payback was. Professor Christopher Llewellyn Smith is a 51-year-old theoretical physicist and cross-country Blue from Oxford who became director general of Cern in January. He has a rapid, precise manner - not without humour - and the faintly mid-Atlantic speech of the globe-trotting academic. He did not try to blind me with science, choke me with muons, gluons and quarks of colour, charm and spin, nor dazzle me with the infinitely large and infinitesimally small quantities his profession trades in. So, endeavouring to look my most alert, I asked: What will the Higgs boson do for the taxpayer? 'It is one very, very major step in understanding the way the universe is put together,' he replied. 'If you ask why anyone should be interested, I think there are three parts to the answer. 'First, the subject is justified as the pursuit of pure knowledge. I mean, it's part of our culture.' He quoted a remark of the first director of Fermilab who, asked by a US congressional committee what the lab contributed to the defence of the nation, replied: 'Nothing. But it makes it worth defending.' 'It's part of mankind's history to be curious about how things work,' the professor added. 'We're trying to find out at the deepest level what matter is made of, why the universe is the way it is and not some other way.' His second argument was, not surprisingly, about direct and indirect spin-off. But he did not labour it. The discovery of new fundamental laws of physics usually had important practical applications, such as the discovery of the electron. However, that was getting harder to be sure of, the further physics moved away from everyday experience. 'So I don't think you can justify the expenditure on those grounds.' Technical development was another kind of spin-off. For example, the collision detectors pioneered by Georges Charpak of Cern (and for which he won a Nobel prize in 1992) were used for medical imaging; accelerators were employed for cancer therapy. 'That's not the reason you do it, but it gives some return and you should subtract it from the price. I always say it's a bit like subsidising the theatre in London: it brings in tourists, but that's not the reason you subsidise theatre.' His third justification was education. Flagship projects attracted schoolchildren to science, even if they ended up in engineering rather than cosmology, while graduate students acquired valuable, if expensive, training at Cern. But, I said, the search for knowledge is the real reason? 'It is the real reason, I absolutely agree with that.' For some people the scale of the endeavour alone may be sufficient justification for spending the money. The Large Hadron Collider will be inserted into the biggest of Cern's tunnels, a racetrack several miles longer than the Circle Line of the London Underground. Where it takes a man six hours to walk round, the protons will whip round the circuit 11,000 times a second. Their path is so precisely aligned that even the daily gravitational pull of the moon has to be adjusted for. To get them to fly in a circular path requires six tonnes of magnetic force every metre. The debris of the collisions - including perhaps the Higgs boson - will be detected by machines three storeys high, in a microcosm of what was going on a fraction of a billionth of a second after the Big Bang which began the universe. The Higgs particle was postulated years ago by Prof Peter Higgs of Edinburgh University to explain why some particles are massive, some massless. Llewellyn Smith said it would help us understand why some forces of nature operate over vast distances, others over minute distances, and why matter is clumped as it is. 'This research can tell us why the universe is arranged with islands of stars called galaxies, why it has this architecture. I think these are pretty interesting questions.' And if you do not find it? 'There must be some mechanism. If it's not the Higgs, we don't know what it is. But we're going to discover something else instead which we haven't been clever enough to imagine.' But what about the cost? I asked. Can you not see a point at which politicians will stop being interested? 'I would say that convincing politicans is not so hard. To a certain extent the hardest people to persuade are people in other fields of science because they are - well, jealous is the right word, I guess. 'It's difficult for people doing biology who need only a few thousand pounds, a tiny fraction of what is going into Cern. So you get the argument: why not do biology? It's cheaper than physics. But by the same argument, why not do theology? It's cheaper than biology. There's a rather nice quote from a French boulevardiste, one of whose characters asks why he should pay 15 francs for an umbrella when he can have a beer for two sous.' I thought of the US decision to cancel its Dollars 10bn Superconducting Super Collider in Texas which would have been three times the length of Cern's. Scientific advances were quite cheap in the past, I said. Can we justify our thirst for knowledge indefinitely? 'Well, that's our job in particle physics. We have kept the cost down. The budget of Cern in real terms is less than it was 20 years ago, despite the fact that the number of physicists who work here is five times bigger.' The SFr2.23bn material cost of the Large Hadron Collider will not involve more than about SFr500m of new money: the bulk will come out of Cern's existing budget, currently SFr900m a year, as its other experiments wind down. The two new detectors, costing SFr350m each, may be financed out of university research budgets. 'People sometimes say it's like the opera and should be subsidised at the same level. I think it's more than that, because scientific knowledge is cumulative, it's more like the composition of an opera than the performance, if you like. The discoveries made in the 19th century are still driving today's electrical industry, for example. And those in the 30s are driving semiconductors.' You may be able to appeal to politicians or to national or European pride, I said. But won't taxpayers protest if they can't understand what you're up to? 'That's why I think we have a big obligation to explain what we're doing - for a grand reason and a pragmatic reason. The grand reason is that we'd like other people to share in the pleasure we get in the things we're doing: and if it is a contribution to culture then presumably we can all share it. 'The pragmatic reason, obviously, is if we can't explain then obviously we're going to lose the support.' Of course, I said, I'm impressed you can look at the state of the universe some fraction of a billionth of a second after the Big Bang. But I'd pay a lot more to know what happened a fraction before. 'In a sense the Big Bang is infinitely far away in terms of its energy density. In time it's a finite way away. But we never will really get there. The energy at which one could directly test the theories that put all the forces together is still a factor of about a million, billion away in terms of energy. 'It's an interesting question what is in science and what isn't. I think to paraphrase St Augustine, the most profound question that human beings can ask is: 'why is there something rather than nothing?' 'Now, that question, it seems to me, is beyond the scope of science and probably will always be - though there are scientists who think not. On the other hand, the question we're asking in particle physics is: given that there is something rather than nothing, why is it what it is, rather than something else? And that question I think we may be able to answer.' Would it be better for you if the results are a shock - better than getting the predicted answer? 'Yes. It's paradoxes that show there's a real question there.' So when you find the Higgs boson, it's going to be both a triumph and an anti-climax? 'In a sense to find something different would be more interesting, yes. That's true.' If they find the boson, do you get a Nobel prize? The professor laughed. 'Certainly not. Probably Mr Higgs gets a Nobel prize.' Well, for my fiver, I hope he does.
19940614000000000	FT  14 JUN 94 / Obituary: Jan Tinbergen, a father of econometrics. Jan Tinbergen, the distinguished Dutch mathematical economist, socialist and pacifist, has died at the age of 91. Tinbergen won the first Nobel memorial prize in economics in 1969, jointly with the Norwegian Ragnar Frisch, principally for his seminal work on the application of statistics to economics. His work in this area, for the League of Nations between 1936 and 1938 and published in 1939, marked the birth of modern econometrics. Tinbergen brought three fundamental attributes to his work in economics and economic policy: his training as a mathematical physicist at Leiden University, his social idealism, and his conviction that a better world could be created by applying reason to the operations of government. Of his intellectual power, personal benevolence and moral rectitude there was never the slightest doubt. But his faith in the capacity and benevolence of the state now looks a little naive. Even econometrics, in whose early development Tinbergen played so great a part, was (and, to an extent, still is) controversial. The first of his two volumes for the League of Nations, on fluctuations in investment, was reviewed quite critically by the British economist John Maynard Keynes. But Tinbergen had the last laugh. His second volume presented an economy-wide model of business cycles in the US. Models of this kind were the vehicle through which Keynesian economics was subsequently implemented. Today's economic forecasting industry owes its existence to Tinbergen's pioneering work. But he also made substantial contributions to the modelling of economic growth and to theories of policy formation, economic development and personal income distribution. His most important contribution, after that to econometrics, was the demonstration that, in general, the achievement of a given number of policy objectives requires as many independent policy instruments. This conclusion was reached in parallel by the British economist (and Nobel-laureate) James Meade. Tinbergen was born in The Hague on April 12, 1903, into a remarkable family of scholars. One of his brothers, Nikolaas (Niko), won the Nobel Prize for biology in 1973; another became a professor of zoology. Tinbergen refused compulsory military service in 1927 and was sent to work for almost a year as a prison administrator and research assistant at the official statistics bureau, the CBS. After gaining his doctorate in physics from Leiden in 1929, he went back to work at the CBS, where he started research into economic dynamics and statistical modelling of economies. After leaving the League of Nations, he returned to the Netherlands, staying with the CBS until the end of the second world war. Then, he was appointed head of the newly-established Dutch planning and economic advisory body, the CPB. He resigned from the CPB in 1955, to become a full-time professor at the University of Rotterdam (where he had been part-time between 1933 and 1955). In 1973 he moved to the University of Leiden, before retiring in 1975. He served as an adviser to the World Bank, the Organisation for Economic Co-operation and Development, and UN bodies.
19940725000000000	FT  25 JUL 94 / An economic hero for Tony Blair: America. I suspect Mr Tony Blair, the new leader of the British Labour Party, is keen to keep abreast of US economic ideas. His advisers regard the Clinton administration, for all its failings, as a valuable role model. My advice is to steer well clear of the US economic establishment: there is little or nothing he can learn from the Harvard/MIT-types now in charge in Washington. Intellectually, they have not progressed far from the naive interventionism of the 1960s; and they are recycling old ideas under the unimaginative rubric of 'new Keynesian economics'. The kind of thinker from whom Mr Blair could gain important insights is Professor James Buchanan, the 1986 Nobel economics laureate, now at George Mason University near Washington DC. Mr Blair should not worry that Buchanan cites Hayek as an important influence and considers himself 'fundamentally a libertarian'. In the 1940s British Labour leaders had the courage to embrace the ideas of Keynes, who was hardly a socialist. Half a century later, Buchanan has much to teach social democrats who are struggling to come to terms with the market. The aspect of Buchanan's thought that is likely to have greatest appeal for Mr Blair is his concept of 'constitutional economics'. Most economists analyse economic decisions within a pre-existing institutional framework: the subject is about 'choice within constraints'. Decades ahead of his colleagues Buchanan began to emphasise the broader framework: the 'choice of constraints' as he puts it. Rather than trying to micro-manage economic decisions the government should focus on the rules under which the game is played. Better rules can conceivably improve prospects for everybody. The importance of institutions is now better understood. It has, for example, become a cliche to argue that the Bretton Woods conference of 1944 helped promote global economic growth by creating a supportive framework of rules and institutions; 50 years on, politicians are beginning to grasp that a new institutional structure is required in today's quite different financial landscape. But the ideas of constitutional economics can be applied more broadly. Take training. Rather than planning heavy-handed interventions, Mr Blair should formulate a 'training constitution' - a stable set of rules and institutions, tailored to the 1990s, designed to help young people help themselves. By Labour's undemanding standards, Mr Blair already seems sceptical of the public sector's ability to work economic miracles. Reading Buchanan might greatly enhance that scepticism. He is famous (or perhaps infamous) within the economics profession for having turned the tables on interventionists by arguing convincingly that 'government failure' is a more serious threat than 'market failure'. When Buchanan reached economic maturity in the 1950s, most of his colleagues were just discovering the concept of market failure. They thought they had scientifically proved that free markets achieve optimal outcomes only if the most demanding conditions are met, for example, that economic agents have perfect information and can make transactions costlessly. Since such conditions do not hold in the real world, markets necessarily 'failed'. Government thus had carte blanche to intervene. Although endorsed by the profession's great intellects, it was a nonsensical argument. Markets fail only relative to idealised mathematical models that themselves have no foundation in reality. The practical question is whether there is a better alternative. Buchanan argued there usually is not, because bureaucrats and politicians are more likely to err than markets. In one of many direct hits, he exposed the inconsistency of mainstream economists' assumptions about behaviour in the private and public domains. The orthodox view was that individuals in the private sector strive to maximise their 'utility' or satisfaction but, once they cross the public sector's portals, instantly reinvent themselves as promoters of the public good. Without denying the possibility of selfless action in either the public or private spheres, Buchanan deflated confidence in government by arguing that it was more plausible to assume that politicians and civil servants are typically self-serving. Like the rest of us, they care more about their own careers than the nation's welfare. Buchanan supported this argument with an even more fundamental observation. Government is not a simple entity that can be entrusted to make rational decisions. Modern democratic government is instead a messy conglomerate of disparate interests. Building on work by Knut Wicksell, the great 19th-century Swedish economist, he argued that the appropriate boundaries of the state depend in large measure on arcane details such as voting rules and the structure of legislative assemblies. Roughly speaking the nearer that voting rules approach unanimous consent, the greater the number of functions that can safely be entrusted to government. Under simple majority voting, the favoured approach today, government's scope should be sharply restrained, lest it trample on the rights of minorities. Buchanan is not just a fountain of ideas; unlike many well-heeled Keynesians, he also has the credentials of an authentic Labour hero. Since his family could not afford an elite private college he attended Middle Tennessee State Teachers' College in Murfreesboro, paying his way by milking cows morning and night. The message for the less privileged: stop bleating, start working and you too may win a Nobel prize.
19940702000000000	FT  02 JUL 94 / Rational choice on the menu: Christina Lamb asks Gary Becker about his theories on everyday life - Lunch with the FT. There is something disconcerting about having lunch with a man who can explain your menu selection in terms of rational economic choice. I thought mere whim had decided my choice of the exotic-sounding fettucine with sea scallops. But not according to Gary Becker. The soft-spoken, 63-year-old professor from the University of Chicago pioneered the application of economic theory to everyday life. For the past 40 years, while jeering colleagues concentrated on lofty matters such as trade policy and market behaviour, Becker has devoted himself to devising economic models for why we fall in (or out of) love, get depressed, commit crimes, become drug addicts or buy fast cars. He was vindicated when he became a surprise winner of the 1992 Nobel prize for economics. His latest work, on the formation of preferences, aims to explain why someone like me would order fettucine with sea scallops. We are sitting in Printer's Row, a yuppyish restaurant in a renovated part of downtown Chicago. Actually, with its inoffensive green and red decor, a waitress from Lyons, a Mozart violin concerto on the sound system and an absence of scowling gangsters, it could have been anywhere. Initially, Becker had suggested the university faculty club - but then changed his mind, concerned perhaps that this would seem unimaginative. We each elected to start with the ragout of wild mushrooms, after which he went for the day's special: grilled grouper with a colourful array of oriental vegetables. Recalling that Becker had written: 'Every death is to some extent a suicide' - that is, we are responsible partly for when we die through the foods and drinks we ingest - I took defiant enjoyment in ordering a crisp Californian Chardonnay. He stuck to mineral water and tried to rationalise my taste for sea scallops. 'Like the Freudians, I stress early childhood,' he explained. 'What foods you were given growing up and how that influenced your later preferences. Peer pressure is also important - maybe it was 'in' in your group in England to like shellfish. By eating scallops regularly you keep up, and even raise, your taste for scallops.' 'Is that economics?' I asked, incredulously. From his resigned smile as he answered, I could see Becker was used to this question. 'My view is that economics deals with more than stock prices or inflation. It's a way of thinking about the world and is not confined to material things.' Becker originally wanted to be a sociologist but claims it was 'too hard'. As a graduate economist, he saw potential for applying the more rigorous science of economics to social problems. His basic insight: most people act rationally most of the time. I said this seemed nothing more than common sense. Becker liked that. 'I take it as a compliment. My approach is based on common sense - what's new is where you take the analysis from there, which may give you surprising conclusions. 'Take divorce, for example. Most people think rich people are more likely to divorce than poor people. In fact, it's the opposite. My theory explains that what matters is the gain from staying married. 'In a poor family with the husband unemployed, hanging around, the wife may decide she's better off throwing the bum out. The richer family get much more out of marriage. The wife is contributing - if not in income, then in providing a good home. So, it's more rational to stay married.' An avowed romantic, I was uncomfortable with such dispassionate analysis; Becker, after all, has a wife and four children. 'But what about falling in love. Surely that can't be explained by equations?' He was ready for that one. 'Rational choice can handle that. I can't say that individual A is going to fall in love with B or C, but I can say why people tend to marry people with clear similarity in terms of background, education etc. Moreover, why is it that love doesn't last? I don't deny that people fall in love, I try to incorporate it.' (L represents love in his equations.) I was not about to give up so easily. 'How do you explain people falling in love with the 'wrong' person? If we are concerned only with behaving rationally, why would we ever get involved in difficult relationships like inter-racial marriage?' 'Well,' he replied, 'that's where love etc comes in. But tell me why inter-racial marriages have such an unusually high divorce rate. Rational behaviour does not rule out mistakes.' The sea scallops were no more and I felt I was not getting through to this endearing figure with the domed forehead and detached expression. So, I tried a new tack: 'What about public figures indulging in extra-marital affairs? How could it be rational for someone like (President) Clinton to risk jeopardising a successful career for a one-night stand?' 'I don't have any difficulty understanding that,' he replied. 'The opportunities you're exposed to in a powerful position are enormous, while the risks of being caught are very low . . . My bet is that for everyone brought down, there are a lot who have no trouble at all. Now it's becoming much more risky, I think it will decrease.' Frustrated by the range of human behaviour that fits into Becker's rational choice models, I asked if nothing was sacred. 'Say I decide to squander my pay cheque on a Donna Karan dress, leaving me with no money to live on?' Laughing, he said: 'I have a paper on that. Why do some women want a Chanel suit when they can buy something that looks the same for a sixth of the price? The fact that they know they're wearing a Chanel suit is the important thing for them. That's perfectly rational.' 'Sounds irrational to me,' I said. 'Now you're being too much of an economist,' he replied. 'I fight with my colleagues about this the whole time. Who's to say that the only reason you wear a suit is because it covers your body? What you're wearing is conveying something to the outside world about you as a person, your choices, what you belong to, how successful you are. It's perfectly rational to be interested in that.' I wondered if he could go round the entire restaurant and explain, in terms of rational choice, everything people were eating and wearing, and the relationships they were having. 'That's not my goal. My goal is to try to understand the phenomena of people falling in love, buying Chanel suits or designer jeans. There are a lot of things we can't yet understand through this approach, such as religion or war, though that may be a matter of time.' Over coffee, I ventured to inquire if the Nobel prize-money had tempted him into a little irrational spending. 'Well, it wasn't so much money. It was announced as Dollars 1.2m but declined immediately because the Swedish krona devalued, so I ended up with Dollars 700,000 after tax. 'We've done some modest things, re-modelled the house, acquired a place on Cape Cod. But we still drive a five-year-old Audi. The irrational thing would have been to have spent it.' 'But surely more fun?' I asked. The arrival of the bill left the question hanging. Ever the gentleman, Becker offered to pay before deciding it was more rational to let the FT pick up the tab. A nice man, but his theories seemed suddenly to have made the world less interesting. As he strode away, I changed my mind about splurging the fee for this article on an expensive jacket for fear that it might indeed be a rational act.
19940702000000000	FT  02 JUL 94 / The famous DNA double act: Forty years ago, James D. Watson and Francis Crick made a discovery described as the greatest achievement of science in the 20th century. Christian Tyler tells the story. The professor was galloping back and forth along the base line, returning his coach's slamming serves with an aggressive, short-swinging stab. His pursuit of the ball was single-minded, and impressively nimble for a 66-year-old. A mile or so from this animated scene, scientists at the John Radcliffe Hospital, in Oxford, were concluding a remarkable post mortem examination. They reported that 'Otzi', a Tyrolean hiker overtaken by a blizzard and frozen to death 5,000 years ago, has at least 88 relatives living in the same Alpine region today and other kinsmen dotted round Germany and northern Europe. Therefore Otzi could not be, as some have tried to claim, a Peruvian mummy deposited on the mountain pass three years ago by a practical joker. The professor had been bouncing about the tennis court for half an hour, whooping and exclaiming. Now he collected up his things, thanked the coach, complained that he had not been up to his best but said he was glad to have shed another ounce or two. Meanwhile, a few fields away, a controversy was raging over a cabbage patch. Another group of scientists had been given permission to release on to their test site a genetically-altered virus designed to kill the caterpillar of a pest called the cabbage looper. But a local resident, a materials scientist, had spotted the statutory announcement in the local paper and protested. Was there any guarantee, he wanted to know, that the virus - which contains a gene for scorpion venom - would not attack other kinds of insect or breed with wild viruses? It was the biggest row of its kind yet seen in Britain. The experiment was interrupted. These two trials, like thousands more going on in medicine and agriculture all over the world, are the results of a biological revolution started by the leaping tennis player, James D. Watson, and his colleague Francis Crick. Their discovery of the molecular structure of deoxyribonucleic acid, DNA, the famous double helix, was made more than 40 years ago at the Cavendish Laboratory in Cambridge. It was published in that annus mirabilis of 1953, just before the Queen's coronation and the British team's conquest of Everest. It was a vital link in the chain of discoveries which the late Sir Peter Medawar called in his book Pluto's Republic 'the greatest achievement of science in the 20th century'. Not only did Crick and Watson share the Nobel prize for it but, contrary to their own expectations at the time, lived to see its extraordinary consequences. They are both alive, and both still kicking. Francis Crick, now 78, holds a specially-created research post at the Salk Institute in La Jolla, California. On a visit to London last month to promote his new book he told me: 'The general reaction of younger people - if they don't say it you can see it in their eyes - is 'Good heavens] Are you still alive?'' He recounted how a young woman was selling a car to him and his wife, Odile. On hearing the name she looked suspiciously at Crick: 'Anything to do with DNA?' He confirmed that he was and she exclaimed: 'But I've got a photo of you over my bed]' The former colleagues are a paradoxical pair. Both work in the US, but Watson, the American, is very much an Anglophile. Crick, the Englishman, loves the Californian lifestyle. Rather like the double helix itself, the two spiral strands of which unwind and decouple for replication, their own lives have diverged. Yet beneath the skin they are remarkably similar. Jim Watson is the younger man but looks older. He confessed that he had grown overweight during his long tenure at Cold Spring Harbor, the laboratory on Long Island, New York, where he is director and responsible for raising funds for young medical researchers. But the year he has been spending as a visiting fellow of Lincoln College, Oxford, has allowed him time to get fit and recover something of his former skinny profile. Behind the old man's visage one can recognise the gawky, precocious youth with the large eyes, crooked smile and self-mocking, slurping chuckle who arrived in Cambridge in 1951. Francis Crick's hair is white but the face below it is seamless and young, for all that he has lived the past 18 years on the West Coast. He is still the energetic talker described by Watson in his best-seller, The Double Helix, but there is little trace today of the hyena laugh which so upset Sir Lawrence Bragg, head of the Cavendish laboratory. Nor does he display that characteristic which Watson noted in the famous first sentence of the book: 'I have never seen Francis Crick in a modest mood.' Crick says now: 'I think he meant I was usually exuberant. He just used the wrong word.' Maybe. Although their work separated them long ago, the two men meet occasionally. When they talk about each other now it is with a critical but nostalgic affection - with admiration, too. Watson, the precocious one (he went to the university of Chicago at the age of 15), says Crick has the faster brain. He still professes to be puzzled that the older man, so brimming with ideas, should have taken as long as he did - he was in his mid-30s when they discovered the double helix - to make his mark. Watson has been described as the Boswell without whose book his collaborator might not have become known to the public at all. 'Francis went to the extremes of trying to avoid the press,' he said, 'which I think diminished his importance in the world.' Watson once wrote that Crick would prove to be as important a scientist as Rutherford or Bohr. Had he? 'I think so.' And how does Crick describe his Boswell? 'He is still what you might call the unAmerican boy. He doesn't conform very easily. But he has turned out to be an extraordinarily good scientific administrator, for example, both at raising money and at getting good people. He's very shrewd, in fact.' Both say they owe their present elevated position to the fact that they are Nobel laureates. They shared the prize in 1962 with Maurice Wilkins, a friend of Crick's from the war years, whose X-ray diffraction work on the DNA molecule at King's College, London, was vital to the discovery. There were other benefits, said Crick, one of which was getting past bureaucrats. He described how, scruffily dressed, he went to the US embassy in London for a visa so that he could deliver a lecture in America. The woman behind the desk asked him how he could support himself on one lecture alone and was incredulous when told he was getting paid Dollars 1,000 for it (this was some years ago), and transfigured when she learnt he was a Nobel prizewinner. 'But it doesn't help socially,' said Crick, 'because people treat you as some sort of strange animal. If they find themselves at dinner sitting next to a Nobel prizewinner they worry about what their conversation is like.' Neither man will say that the double helix was the climax of his career, that the rest had been less interesting. Watson maintains that he has derived more pleasure from his books in the long run - the textbooks as well as the best-seller - 'because they were totally my own'. He is writing a sequel to The Double Helix about his life after Cambridge, in which he describes his pursuit of pretty girls and his eventual marriage, at the age of 40, to Elizabeth Lewis. He wants to call the sequel Genes and Girls, if his publisher will let him. 'First I found the perfect molecule and then the perfect woman,' he laughed. Watson returned to the US in 1953, still only 25 years old and feeling, as he wrote later, 'too old to be unusual'. He worked with the distinguished chemist Linus Pauling and taught at Harvard before being appointed to run the Cold Spring Harbor laboratory. Crick stayed on at Cambridge finished his PhD and helped crack the genetic code. Through his research students, Watson is still interested in pursuing genes, especially those which could account for medical disorders such as cancer, Alzheimer's disease, or manic depression. He became part-time director of the human genome project in Washington, DC, but was sacked by the parent body, the US National Institutes of Health two years ago, allegedly for a potential conflict of interest between his professional work and private shareholdings in biotechnology companies. But the real reason, he said, was a clash between his scientific opinion and a bureaucrat's power game. In his characteristically blunt way, he had publicly disagreed with the 'absurd' policy of patenting short sequences of DNA, which he argued were commercially valueless. These days he is interested in medical ethics. By this, he does not mean what most people mean. Of course, he said, there is a problem in deciding how far people should be warned of their genetic predisposition to particular illnesses. 'But the major ethical problem - one which faces the British government, for example - is whether it will spend the money to ensure that its citizens have as healthy babies as possible. That's the major one.' In other words, he is worried not that legislators will let scientists interfere too much, but interfere too little. 'We have the wrong priorities,' he said. 'We tend to get stuck on something about which you can argue for ever. But does a family want a child that can't learn? Are we going to help people have functional families? It's just common sense. I think the problem will disappear if we ask the right questions.' Watson speaks with feeling: one of his own two sons was born with a serious learning handicap. And here the similarity of thinking between Crick and Watson, so productive at the Cavendish all those years ago, becomes apparent. Both are frank and passionate materialists who run a mile from the comfort of metaphysical explanations. 'Are we similar types? Yes,' said Watson. 'I think we think in the same way. Francis always thought much quicker and better than I do. But we sort of have similar reactions to people.' To the big questions also. Francis Crick's latest book, published in May, is called The Astonishing Hypothesis. It is the product of his new career at the Salk Institute as a neuroscientist specialising in visual perception. (Watson has plans for similar research.) Crick's hypothesis is simply that human consciousness, personality, the soul  -whatever you will - are entirely explicable in terms of brain activity. Approaching the mystery of consciousness with the same ruthlessness that the pair applied to the secret of life, Crick argues that the only way we can explain ourselves to ourselves is to get right inside, to the brain cells, and look. 'To very religious people I say: we don't know which way this thing is turning out. It may turn out there is something immaterial that we don't know about.' For example there was a serious difficulty in accounting for qualia - phenomena such as the 'redness' of red. So human beings are machines? 'You mustn't call us machines,' said Crick. 'I would put it the other way round. We should be saying 'Isn't it remarkable that this thing inside my head does such wonderful things]' We won't destroy the wonder. We are simply trying to remove the mystery.' Crick's remark could be an appropriate epitaph, for one thing is certain. The two old men of the double helix will not be around to see the results.
19940822000000000	FT  22 AUG 94 / Linus Pauling, leader in chemistry: Obituary. Linus Pauling, one of the great figures of 20th century chemistry, has died at the age of 93. He was the only person to win two solo Nobel prizes in different disciplines. Pauling won the Nobel Chemistry Prize in 1954 for his work on chemical bonds. This gave scientists a theoretical framework for understanding the forces that hold atoms together - and a practical guide for predicting the structure and shape of new molecules. Pauling's research is the basis for the computer programs used today in the pharmaceutical industry to design new drugs. His second Nobel award was the 1962 Peace Prize, in recognition of his tireless campaigning against nuclear weapons testing. His anti-bomb petition to the United Nations, signed by 11,000 scientists from across the world, helped persuade the US, UK and Soviet Union to sign the 1963 atmospheric test ban treaty. But Pauling is probably just as well known today for his scientific crusade over the past 25 years in favour of vitamin C. He believed that huge doses of vitamin C - two spoonfuls per day, or hundreds of times more than the officially recommended daily allowance - could help stave off illnesses from colds to cancer and prolong healthy life by more than 20 years. Pauling himself was a good walking advertisement for mega-doses of vitamin C. He remained mentally and physically active into his 90s, writing a dozen research papers a year, and his gaunt figure, topped with blazing blue eyes and bright white hair, was a familiar sight at scientific meetings. However, Pauling did not win the scientific and medical establishments over to his view of the virtues of vitamin C. Although mainstream researchers have become more aware of the health benefits of vitamins since Pauling began campaigning, most regard his claims as grossly exaggerated. Indeed some privately pointed to Pauling as a warning to successful scientists not to become obsessed with cranky ideas in their old age. Pauling was born, bred, lived and died on the US West Coast. He grew up in Oregon, the son of a small town pharmacist who used the slogan: 'Pauling's Pink Pills for Pale People' and from whom he derived his love of chemistry. After studying chemical engineering at Oregon State University, he moved to the California Institute of Technology for graduate studies in 1922, at the age of 21. Cal Tech was to be Pauling's base for the next 41 years, during which he developed his Nobel-prize winning theories of chemical bonds and struc-tures. Chemists will remember Pauling above all for his book, The Nature of the Chemical Bond, published in 1939 and without doubt the most influential chemistry book written this century. He died on Friday night at his Californian ranch in Big Sur.
19940820000000000	FT  20 AUG 94 / Books: A quantum leap - AC Grayling discusses the beauties of nature. THE QUARK AND THE JAGUAR by Murray Gell-Mann Little, Brown Pounds 18.99, 392 pages BLACK HOLES AND TIME WARPS: EINSTEIN'S OUTRAGEOUS LEGACY by Kip Thorn Picador Pounds 20, 619 pages Imagine a medieval stonemason resting from his labours half way up a Gothic cathedral spire. He gazes - if he is a man of sensibility, he marvels - at the world spread around him. What does he see? Leaving aside details like urban sprawl, factory chimneys and passing aircraft, he sees much the same world as we now do. But in another sense of 'see' we see the world in a way inconceivable for him, because the stories told then and now about the nature and origins of the universe are vastly different. Both stories are strange and in their way beautiful; but the one told by modern science is infinitely stranger and more beautiful than any hitherto dreamt by mankind. A swarm of popularising science books reaches the market each year, seeking to give the general public an understanding of the latest developments. Most are good, because most scientists and their commentators are an intelligent crew who enjoy what they do. But these two additions to the swarm are special: for their authors are extremely distinguished original contributers to the scientific endeavours they describe. These are reports from the cutting edge, and they are presented with eloquence and style. Murray Gell-Mann won the Nobel prize for physics in 1969, and later helped establish the Santa Fe Institute, an interdisciplinary foundation devoted to the study of 'complex systems' as various as quantum mechanics, the human body, and international economics. The key concepts which interest him are simplicity and complexity. The fundamental units of matter - quarks and leptons - are simple entities. Everything built out of them is complex; but among the most interesting complex things are those possessing a capacity to change in response to information about their surroundings. Gell-Mann's aim is to understand these 'adaptive systems', of which biological entities are a prime example, by tracing the chain of relationships between them and simpler levels of the world. Gell-Mann's main theme is the interaction between physics and chance. Our present understanding of nature's fundamental laws, he says, promises that we might soon have a unified theory of all particles and forces. Chance enters the picture because these laws are quantum-mechanical; they offer only probabilities. So nature is indeterministic, a feature magnified by the phenomenon of 'chaos', in which small imprecisions in data about initial conditions give rise to huge indeterminacies in prediction-as exemplified by the difficulties of weather forecasting. But these factors mean that at certain points in the universe's history conditions are right for the emergence of complex adaptive systems. The same concepts that apply to the phenomena of physics can be used here also, to explore evolution both in the biological and cultural spheres. Here Gell-Mann's ideas are at their most radical. They describe how the evolution of adaptive systems works best in conditions poised between order and disorder. There must, he says, be many places in the universe where the chain of connections between simple and complex levels has produced something similar to life on earth. But even so - and here, in the third part of his book, he turns from science to politics - there remains an urgent need to preserve as much of the biological diversity of the world as possible; which will only happen, he says, if there is a major change in our economic and technological lifestyles; for man and his world are ceasing to be in adaptive relationship with each other, to the peril of both. There is no environmental message in Kip Thorn's book, but it is equally gripping. Thorn was one of the physicists who brought a weird and awesome astronomical monster to the attention of an astonished world: the 'black hole'. In his delightfully clear account he explains what black holes are and relates the history of the scientific work which discovered them. A black hole is a puncture in the universe exerting such a huge gravitational attraction that it sucks in everything near it. Nothing that slips over the 'horizon' of a black hole ever escapes, including light; which explains the name. At the centre of a black hole is the remnant of a star which died by imploding on itself. This tiny core is hugely massive; space itself is warped by its gravitational pull, so even the nothingness between the core of a black hole and its surrounding envelope of blackness is a vast distorted twist of pure space. The study of black holes is revolutionising scientific understanding of nature. Thorn predicts that in coming years the results of investigations into them will unlock the inner structure of matter - the same goal at which Gell-Mann, from the different direction of nuclear physics, aimed in much of his work. Both these books give one the dizzying sense that science is poised on the brink of a new world of discovery; a world stranger and still more beautiful than anything imagined yet.
19941029000000000	FT  29 OCT 94 / The Nature of Things: Writing with atoms. A new generation of microscopes, more powerful than scientists would have believed possible before the 1980s, is enabling researchers not only to 'see' individual atoms but also to pick them up and move them around. These microscopes will be vital instruments for the coming era of 'nanotechnology', in which miniaturisation will produce atomic-scale structures thousands of times smaller than those used in microelectronics today. On that scale, all the words in the Bible could be written on the point of a pin. (A brief explanation of the terminology used in nanotechnology: the word comes from the Greek nanos for dwarf. The fundamental unit of the field is the nanometre, one billionth of a metre.) The first of the new instruments, the Scanning Tunnelling Microscope, was invented in 1981 by Gerd Binnig and Heinrich Rohrer at the Swiss laboratories of IBM, the American computer group. The STM was a wonderful leap of scientific imagination, recognised unusually promptly with a Nobel Prize for Physics in 1986. Conventional microscopes work by focusing beams of radiation or particles. Optical instruments are limited by the wavelength of visible light, which is about 500nm; even a perfect lens cannot focus on a point smaller than this, so they cannot see atoms. To achieve greater resolving power, microscopists moved to electron beams and X-rays, which have much shorter wavelengths, but they use penetrating high-energy radiation which is unsuitable for imaging atoms on surfaces. Binnig and Rohrer decided to use 'electron tunnelling', one of the slightly bizarre consequences of quantum theory. When a low voltage is applied to two conducting materials which are extremely close together but not touching, electrons 'tunnel' through the gap; the resulting electric current is highly sensitive to the distance between them. The instrument built by the IBM researchers had a stylus with the sharpest possible tip - a single atom - which scanned a metal surface. The variations in tunnelling current revealed the ups and downs of the atoms on the surface. The STM could only give images of materials that conduct electricity. The next step was the Atomic Force Microscope invented by Binnig and colleagues in 1985 to look at non-conducting materials. The AFM scans a tip attached to a thin metal cantilever across the sample, and gives an image based simply on the repulsive forces between the atoms at the end of the tip and those on the sample's surface. More recently, the STM and AFM have spawned a variety of other instruments, known generically as Scanning Probe Microscopes, which produce atomic images based on thermal, magnetic, optical and other interactions between the tip and sample. By speeding up the scanning rate, scientists have even made 'atomic movies', showing how atoms move around on heated surfaces. An estimated 3,000 SPMs are now operating worldwide, for a vast range of applications, and the number is increasing. Most are used for research into surfaces, helping scientists understand processes such as corrosion. They are also moving on to production lines in the electronics industry, inspecting semiconductors and other materials for surface quality. In biology, SPMs have imaged the double helix of the genetic material DNA and distinguished the chemical 'letters' which hold our genetic code. If the technique can be speeded sufficiently, it may be possible to read genes by microscope, instead of using chemical-based analysis. But much of the excitement about SPMs concerns their potential for manipulating atoms. Researchers at IBM's Almaden laboratories in California showed the way in 1990 when pushed atoms of xenon across a nickel surface with an STM tip, one by one, and arranged them to spell the company's initials in atomic letters 5nm high. Such demonstrations show that, in principle, data could be stored in ultra-compact 'atom-scale memories'. Decades of work will be required to bring atom-scale devices based on SPMs to practical fruition. In particular, the speed with which atoms are moved and scanned will need to increase millions of times. But it is far from certain that SPMs are the main route to an atom-scale future. Alternative methods of nano-construction are already further developed, such as laying down atoms by molecular beams in a vacuum. These are less sensitive than SPMs but far faster. The future for the new generation of microscopes may lie more in observing nano-structures and assembling prototype devices than in mass production. However they have transformed the way scientists see the world in miniature.
19941017000000000	FT  17 OCT 94 / FT Guide to Game theories. Last week the Nobel Prize for Economics was awarded to three 'game theorists': John Harsanyi, John Nash and Rheinhard Selten. What is game theory? Game theory is about how people make decisions when they have to take other people's responses into account. Businessmen often have to make this type of calculation - whether or not it makes sense to enter a new market, for example, or lower prices, may depend on how other companies react. Politicians, trades unions and parents all come up against the same thing whenever achieving a desired result means correctly guessing how others will respond. Before game theory, economists had observed interactive decision-making in the real world, but there were no general models for examining the way people were likely to behave. Where do the games fit in? Do game theorists really think life is like poker? Not really. Most of the games used are not games people play, but stylised models which capture some element of the theory. The 'prisoner's dilemma', probably the best-known game, is a case in point. Strictly speaking it is not a game but a paradox about co-operation. The original, as conceived by Albert Tucker in 1950, describes two men getting arrested for a crime. After locking them in separate cells, the sheriff explains that they can either confess to committing the crime with the other man, or refuse. If neither confesses, both will get two years in jail. If only one confesses, he will go free while his accomplice gets 12 years. If both confess, however, each will get four years. The problem is that each will inevitably confess, even though they would both be better off if neither talked. Does game theory provide an answer to the paradox? In technical terms, the outcome is a 'Nash equilibrium'. This means that each prisoner would choose to confess even if he knew what his friend had decided to do. Elements of the prisoner's dilemma crop up a lot in real life. Take cartels. In order to keep prices artificially high, all producers might agree to produce only a certain quantity of goods. Afterwards, however, it makes sense for each producer to try to gain extra profit by over-producing. In the end, all lose out because the price stays low. Game theorists do not really resolve problems like this, but they provide formal ways of analysing them. How does that help? Can you learn anything if you don't understand the maths? By abstracting from the details of particular cases, the models can sometimes identify ways to change the game to deliver a better outcome. Allowing the game to be repeated, for example, may help the players get it right the next time. In the case of the cartel, producers might behave differently if they believed they would need to deal with the other producers again. Another possible solution is to change the 'pay-off structure', so that each individual faces a higher penalty if he or she decides to renege on the deal. At its simplest, game theory shows that individual incentives matter. Sometimes the lesson is to change the incentives to get a better result. At other times it shows that the players would be better off not playing the game at all. It still sounds rather abstract. Are there any specific cases where game theory has been used? Game theory is still a relatively young field. John von Neumann and Oskar Morganstern introduced many of the central ideas in a book published in 1944. Most of the work since has been devoted to refining their ideas to produce a more sophisticated set of theoretical tools. But academics from other fields have applied the analysis more broadly. Henry Kissinger was one of the pioneers, using ideas from game theory in studies of international diplomacy in the early 1960s. Business strategists, political scientists and macro-economists have followed, using the same techniques to analyse anything from industrial disputes to negotiating international environmental agreements. Give me specific cases. Game theory is hampered by the fact that the models themselves are very difficult for non-specialists to follow. But in a sense, the lessons of the theory are everywhere. UK long-term interest rates are currently higher than they might be, because Britain's chancellor of the exchequer cannot credibly commit himself to never inflating the economy for short-term political gain. Costly strikes happen because neither workers nor employers can trust the claims of the other side. Game theory has explained why these games are lost; it has yet to show how to win them.
19941013000000000	FT  13 OCT 94 / Nobel prizewinner list grows. North American dominance of the 1994 Nobel prizes was underlined yesterday when two Americans and a Canadian won the awards for physics and chemistry. The physics prize was shared by Mr Bertram Brockhouse of McMaster University in Hamilton, Ontario, and the Mr Clifford Shull, of the Massachusetts Institute of Technology, for their pioneering development of neutron scattering techniques. Their work, carried out 40 years ago, has paved the way for the development of new materials such as ceramic superconductors. The chemistry prize went to Mr George Olah, of the University of Southern California, for his contributions to carbocation chemistry. 'In simple terms Clifford Shull has helped answer the question of where atoms 'are' and Bertram Brockhouse the question of what atoms 'do',' said the Royal Swedish Academy of Sciences when making the SKr7m (Pounds 583,300) award. The science academy said the work of the Hungarian-born American, Mr George Olah, had been widely recognised among organic chemists and that his work on carbocations - positively charged hydrocarbons - had won a prominent position in modern textbooks. Hydrocarbons are used to make gasoline, pharmaceuticals and plastics. Seven out of the eight Nobel prizewinners announced so far have been North American or North America based.
19941012000000000	FT  12 OCT 94 / Games of chance set up Nobel prize in economics. Three academics from the US, Germany and Hungary won the Nobel economics prize yesterday for their work deriving economic lessons from the dynamics of games. The winners are Dr John C. Harsanyi, born in Budapest and now at the University of California at Berkeley, Dr John F. Nash, of Princeton University, and Dr Reinhard Selten, now at the University of Bonn. They are the first economists to win the prize from the field of 'game theory', one of the biggest trends in economics of the past 30 years. Game theorists draw on games such as poker to build models of situations in which people may base their decisions on how they expect others to react. Work by yesterday's winners has since been applied to everything from corporate pricing strategy to international disarmament talks. All three theorists tend to express their ideas in complex mathematical models. But the basic themes are relatively simple. A Nash equilibrium, formulated by Dr Nash in 1951, defines stalemate in a 'non- co-operative' game. In poker, this would mean that each player would make the same bid, even if they could see everyone else's cards, and knew what everyone else was going to bid. Nothing that a player could do would affect the other players' bids. Dr Harsanyi stretched the concept to situations in which some players know more than others; for example, where one person might look at another player's hand. He also pointed out that games might be expected to run more smoothly if everybody agreed on the rules at the start. Dr Selten took game theory a step further, showing how players' behaviour might change if they knew they were going to play again the next day. He also contributed the 'chain-store paradox', which helps to explain why well-known, profitable players may be willing to lose a lot of money to scare off minor competition, if it helps to stop others from trying the same thing. Together, the three economists have helped to show that many problems can be construed as games. Work continues on applying these techniques to real life. Editorial Comment, Page 25
19941011000000000	FT  11 OCT 94 / Nobel medicine prize awarded. The Nobel Prize for medicine was awarded yesterday to two Americans, Alfred Gilman and Martin Rodbell, for pioneering work on the role of proteins in human cell communication. Sweden's Karolinska Institute, which announced the SKr7m (Pounds 602,000) award, said the discovery of G-proteins and their links with the development of disease had been 'of paramount importance' opening up a 'new and rapidly expanding area of knowledge'. The institute described the G-protein as a biological 'traffic light' which regulates the body but can cause illness if it breaks down. Mr Rodbell, 68, of the National Institute of Environmental Health Sciences in North Carolina, showed in the 1960s and 1970s how messages were carried between cells. His work was later developed by Mr Gilman, 53, currently chairman of the pharmacology department at the University of Texas.
19890302000000000	KONRAD LORENZ; AUSTRIAN SCIENTIST WHO WON NOBEL. Konrad Lorenz, the Austrian scientist who won a Nobel Prize for his pioneering studies of human and animal behavior that led to theories of man's innate aggressiveness, has died at age 85. The Austrian Academy of Sciences said Tuesday that Lorenz died Monday night at his home at Altenburg, about 30 miles northeast of Vienna. The Austria Press Agency said he died of kidney failure. Lorenz, considered Austria's most famous scientist, years ago could be found paddling in his swimming trunks among a flock of greylag geese, his favorite research objects. "If you want to understand geese, you have to live with them," he would explain. He used to say the research into animal behavior that won him the Nobel Prize for medicine or physiology in 1973 started when he was 5, as he quacked his way to a relationship with a duck he had raised. "It was this contact which created the soil on which all my work has grown," said the white-haired, bearded bird lover, who gained a reputation for unconventional research methods and who held doctorates in medicine, zoology and psychology. Lorenz turned to research in animal behavior shortly after obtaining his medical degree. He had become an animal lover as a child, collecting a variety of pets at his expansive boyhood home outside Vienna. Up to 200 jackdaws, hawks, ravens, cormorants, storks and other wild birds also frequented the home where Lorenz returned in his old age. His first important findings concerned the social life of birds. Those studies convinced him that many aspects of bird behavior were innate and instinctive, rather than learned. His views were controversial, and they became even more so when he suggested that such instinctive behavior might be important in humans, too. One of his best-known findings was that young animals will become strongly attached to their biological mothers, a process known as imprinting. He showed that the process could be altered, however, by demonstrating that mallard ducklings would happily follow a human who greeted them shortly after birth and imitated a mother's quacking. Lorenz's theory of comparative ethology -- the study of animal and human behavior through comparative zoological methods -- linked him to the ideas of Charles Darwin. Like Darwin, he held that physical characteristics of species and hereditary behavior stem from trying to adjust to their surroundings to boost chances of the species' survival. Born in Vienna, the son of a surgeon, Lorenz was awarded his first doctorate in medicine at age 25. Further studies in zoology and psychology followed in Vienna and New York, culminating in a 1933 doctorate based on his research on the behavior of birds. In 1939, Lorenz was given a chair in psychology at the prestigious Immanuel Kant University in Koenigsberg, then a German town and today the Soviet port of Kaliningrad. His tenure there and publications during that time led in later years to allegations that Lorenz was a Nazi sympathizer. When accepting the Nobel Prize, which he shared with Karl von Frisch and Nikolaas Tinbergen, he apologized for a 1940 publication judged to reflect Nazi views of science, saying that "many highly decent scientists hoped, like I did, for a short time for good from National Socialism, and many quickly turned away from it with the same horror as I."
19900309000000000	'MOLECULAR SCISSORS': NEW HOPE FOR AIDS; MEDICINE: THE ARTIFICIALLY PREPARED FORM OF RNA INTERFERES WITH THE INFECTION OF CELLS BY THE VIRUS.. An innovative "molecular scissors" that interferes with the infection of cells by the AIDS virus has been developed by researchers at the City of Hope National Medical Center in Duarte. Molecular geneticist John J. Rossi and his colleagues report today in the journal Science that they have used a specially prepared form of RNA (ribonucleic acid) to create the scissors, which snips apart the virus' own RNA before it can be used as a blueprint for replication of the virus. The scientists have already inserted a gene for the artificially prepared RNA, called a ribozyme, into cultured human cells and shown that it sharply reduces infection of the cells, which should halt the progression of the disease. They are now working with Vestar Corp. of San Dimas to develop a way to deliver the ribozymes into the white blood cells of AIDS victims, where it would halt the replication of the virus. Nava Sarver, who is in charge of the National Institutes of Health's program for rapid development of new AIDS therapies, predicted that human trials could begin in as little as three years. The principal advantage of the technique is that it is extremely selective in its activity, attacking only the viral RNA and leaving the cell's own genetic materials intact. This approach to therapy should therefore produce virtually no side effects, unlike currently used drugs such as AZT. Many researchers believe that this approach may ultimately provide a completely new way to attack all kinds of viral infections, which are now almost impossible to treat. "It's a promising approach," said molecular biologist Sidney Altman of Yale University, "but we have to keep in mind that every year many promising approaches are discarded because they don't work." Perhaps ironically, the lineage of the ribozymes that would be used to attack humanity's newest infectious nemesis can be traced back to the oldest molecules on Earth, the ones that were present when life first arose. Many researchers now believe that the first life on Earth was composed entirely of RNA, which combined the functions of DNA (deoxyribonucleic acid), which carries the genetic information necessary for life, and proteins, such as enzymes, which carry out the biochemical functions necessary for life. Previously, researchers had believed that the primary function of RNA -- except for a few viruses, such as the AIDS virus -- was to serve as an intermediate between DNA and proteins. RNA provides a sort of working blueprint for cellular machinery, a copy of genetic information from DNA that is used in the production of proteins. In the early 1980s, however, Altman and molecular biologist Thomas Cech of the University of Colorado in Boulder independently discovered that RNA could act in the same fashion as enzymes, cutting apart RNA and moving it around in cells. Their discovery earned them the 1989 Nobel Prize for Chemistry. Immediately, many researchers saw the ribozymes as a new way to attack viruses and began developing ways to use them. Rossi and his colleagues are apparently the first to report success. Rossi and his associates took a fragment of RNA -- the "scissors" portion of the molecule -- from a plant and combined it with an artificially synthesized RNA fragment that would bind only to RNA that serves as a blueprint for a protein crucial to replication of the AIDS virus (which is known formally as the human immunodeficiency virus or HIV). In the test tube, they found that the ribozyme thus produced would in fact bind to the target RNA from the AIDS virus and cut it. They next used genetic engineering techniques to insert the gene for the ribozyme into human cells grown in a test tube. The cells produced the ribozyme and, when the researchers infected the cells with HIV, the ribozyme prevented the virus from reproducing and spreading. Most important, he said, the ribozyme "only targets what you ask it to target. And it's a natural molecule, so the cell sees it only as RNA, not as a toxic drug." Vestar and a half-dozen other companies around the country are developing a promising new way to deliver ribozymes. They encapsulate the ribozyme in an artificial sphere, about one-hundredth the size of a red blood cell, called a liposome. The liposome is composed of naturally occurring fat molecules that surround the drug to be carried and protect it from degradation in the blood stream. Theliposomes are also readily taken up by cells, so they provide a method of injecting the drug into target cells. Inside the cell, the fat molecules are absorbed, freeing the drug. The liposomes, like the ribozymes, are still largely experimental, although Vestar just received approval in Italy to market an anti-fungal agent carried by lipsomes. Consequently, said biochemist Sean Sullivan of Vestar, a great deal of testing will be required before the technique can be studied in humans. "But in all fairness to NIH and FDA (the U.S. Food and Drug Administration), any therapeutic that looks promising gets put on a fairly fast track. So the process could be accelerated."
19900802000000000	INTERFERON FOUND EFFECTIVE AGAINST HEPATITIS B. Interferon is the first treatment to relieve and cause remission of lingering hepatitis B infections, the leading cause of cirrhosis and liver cancer and one of the world's biggest killers, researchers have found. A study found that injections of the natural protein can stop the hepatitis B virus from destroying the liver in almost half of the people who are chronically infected. One in 10 undergoes remission. Until now, there has been no treatment for the hepatitis B virus. While interferon clearly does not help everyone, having any therapy at all is considered to be an important step in controlling the infection. "This is an encouraging result. All of us would feel a lot happier if we had a better treatment. This spurs us on to find that," commented Dr. Baruch S. Blumberg of the Fox Chase Cancer Center in Philadelphia. He won the Nobel Prize in medicine in 1976 for identifying the hepatitis B virus. The latest research, conducted on 169 people at 12 hospitals, is the first large-scale comparison study of interferon for hepatitis B. It confirms several smaller studies suggesting that the treatment works. Other studies have also shown that interferon works against hepatitis C, another serious but less common variety of the virus. On Tuesday, an advisory committee of the U.S. Food and Drug Administration recommended that interferon be marketed for hepatitis C. "We can be relatively sure what doctors will find in practice, said Dr. Robert P. Perrillo of the St. Louis Veterans Affairs Medical Center, the principal author of the study. Perrillo said that 10% of hepatitis B patients will undergo remission "and 40% or 50% will be made better and their liver disease will be stopped in its tracks." The results were published in Thursday's New England Journal of Medicine. An estimated 1 million to 1.5 million people in the United States are long-term carriers of the virus, and at least half of them have liver disease. Worldwide, 300 million people, or 5% of the population, are chronically infected.
19891008000000000	THE GOOD HEALTH MAGAZINE; MEDICINE; DIAGNOSTIC WIZARDRY; A REVOLUTIONARY TECHNIQUE CALLED MAGNETIC RESONANCE PROBES THE BODY'S INNER SECRETS BY LISTENING TO TISSUES 'TALK.' WITHOUT A KNIFE OR X-RAYS, DOCTORS NOW CAN DETECT DISEASES AND MONITOR THEIR RESPONSE TO THERAPY. THE PROCESS SHOWS DRAMATIC PROMISE FOR TREATING EVERYTHING FROM CANCER AND HEART ATTACKS TO BRAIN AND SPINAL INJURIES. Every few weeks Dr. Brian D. Ross leaves his laboratory in Pasadena and takes off for San Francisco on an unusual mission of mercy. On these trips the 50-year-old physician-researcher is accompanied by a seriously ill though mobile cancer patient. When their commercial jet lands, doctor and patient head directly for a nondescript factory building on the waterfront near the airport. When Ross and his patient -- call him Mr. M -- arrive at their destination, the headquarters of Diasonics Inc., a manufacturer of high-tech medical equipment in South San Francisco, they go immediately to a back room dominated by a large steel-box-type structure. Inside sits a doughnut-shaped contraption about the size of a small van. While Ross waits in a nearby control room, hovering over video monitors, M sheds his watch and wallet, slips into a loose-fitting examination gown and mounts a cushioned platform on which he can be slid into the doughnut. As the device swallows him up, only his stockinged feet extend out. For the next hour, while the huge device thumps and knocks, M lies inside it, silent and motionless. Actually, since only a few inches of space are between him and the circular all that surrounds him, he can do little else. In the control room, Ross intently watches as successive slices of M's brain flash onto the screen. Occasionally he shouts words of encouragement to his enclosed patient: "Very good, just a few minutes more." It's not a particularly cheerful assignment for Ross, a distinguished, affable British scientist who recently joined the staff of the Huntington Medical Research Institutes. His patient has a malignancy of the brain, a tumor so large it cannot be removed by surgery or treated by radiation or chemotherapy. For the patient, the conventional weapons of oncology have been exhausted. "I suppose you could say that by any existing medical measure," Ross says, "he's . . . under a death sentence." Yet the Huntington's doctors have not given up on M. As part of a bold experimental program for patients beyond the pale of other treatments, he is receiving a radical new therapy. Its object: to stir the patient's own immune system back to life, so it can fight the growing cancer. M's doctors at the Huntington Medical Center have taken some of his white blood cells, or lymphocytes -- part of the immune system's weapons against invaders -- and mixed them with interleukin 2, a naturally occurring chemical messenger used by the body to prod the lymphocytes into renewed activity. Human interleukin 2 is so hard to obtain in any quantity that doctors are forced to use an identical, genetically engineered substitute. The mixture has been in-jected directly into M's tumor in hopes that the revived lymphocytes will begin attacking the rapidly dividing cancer cells. Is the novel treatment working? Has it reduced the size of tumor? "X-rays can't really show us," says Ross. "By the time we could detect a change, it might well be too late." The only other method would be to open the skull to take a biopsy. But such a surgical procedure is out of the question for the severly weakened patient. So Ross must use some other means to peer inside M's brain. That is the purpose of their trip to San Francisco. The examination of M involves an experimental technique called Magnetic Resonance Spectroscopy (MRS). It is vaguely reminiscent of a CT(computed tomography) scan, which uses X-rays and computer technology to provide views of virtually any part of the body a physician may want to see. But the similarity is only superficial. The machine doesn't probe with X-rays. It ferrets out the body's inner secrets by listening to its own signals -- the faint emissions given off by its constituent atoms and molecules, including those of M's massive tumor. To get the tumorous tissue to "talk" -- to reveal whether it has been affected by the experi- mental treatment -- the machine relies on an extremely intense magnetic field, thousands stronger then the earth's, accompanied by pulses of radio waves. The pulses evoke faint electromagnetic echoes from M's tumor, which are a tip-off to its chemical state. This diagnostic wizardry is based on a technique known as nuclear magnetic resonance. The idea, dating to the 1940s, is old hat to physicists and chemists; Stanford's Felix Bloch and Harvard's Edward Purcell shared the 1952 Nobel Prize in Physics for developing it. It has long been used for studying nonliving materials. But only now is it beginning to touch diagnostic medicine, studying living things. Already the results are little short of revolutionary. As Ross explains, "We're able to see aspects of living tissue that have never before been visible other than by cutting or other invasive techniques. The potential of the technique is enormous. If we can monitor the biochemical processes of a disease noninvasively, it will surely give us an early insight into the nature of the disease and its response to treatment." Magnetic resonance holds promise not only for cancer, but for heart attacks, brain and spinal injuries and a variety of muscle-weakening diseases including multiple sclerosis, researchers say. The revolution of magnetic resonance -- doctors have dropped the word "nuclear," lest it unnecessarily frighten their patients -- is taking shape in two distinct ways: MRS, which pinpoints and measures key bodily chemicals, like those that may be feeding the fires of M's brain tumor. And MRI (magnetic resonance imaging), which produces actual images, X-ray-like slices of the body. Though barely a decade old, MRI is clearly one of the hottest areas of diagnostic medicine. Some 1,200 scanners are in use around the country (costing up to $3 million each), and MRI is rapidly closing the gap with CT scanning as a way of probing the body. In the next few years, the number of machines may well double as manufacturers such as General Electric, Philips, Pickering and Diasonics, all of whom currently manufacture magnetic resonance devices, compete for what is already a billion-dollar-a-year scanner market. "It's been taking off like a rocket," Ross says. The enthusiasm of doctors for the new technology is easy to understand. MRI not only avoids potentially harmful ionizing radiation such as X-rays, but also produces images of astonishing clarity, revealing the outlines of soft tissue like tumors, which are beyond the reach of X-rays and could be studied until now only by biopsies or the injection of radioisotopes. The idea of magnetically created images was first proposed in the United States after the advent of the required superconducting magnets (typically chilled by liquid helium down to -450 degrees Fahrenheit, only four degrees above absolute zero) and high-speed computer graphics. But the actual development of the new technology was left to the British. In 1973 a group in Aberdeen, Scotland -- an offshoot of a pioneering team at the University of Nottingham -- obtained the first whole-body image of a living creature using magnetic resonance: It was a cross-section of a mouse. But the British mouse didn't roar for long. Leadership in the field quickly passed back to the United States. "We British seem to have a gift for letting technology slip out of our grasp," says Ross, who is himself joined the brain drain of workers in the field when he came to Huntington last year to direct its spectroscopy unit. "Each of the major groups in the States has been headed at one time or another by an Englishman," Ross says. Under the leadership of Ross's American colleague, Dr. William G. Bradley, Huntington's imaging unit had already become the busiest in the world. Since it began operating in 1983, it has performed more than 18,000 MRI scans. But it is MRS that Ross and his colleagues in the United States and abroad believe may hold even greater promise. Though it has actually been around longer than MRI, MRS is far less familiar and is in its experimental infancy. It doesn't produce images -- "just squiggles," says Ross, but to knowing eyes like his, they are as meaningful as any picture. Ross's squiggles are the spectra -- or fingerprints, if you will -- of the body's chemicals. Jogged by radio waves in the presence of the magnet's powerful field, each of the target compounds responds in a uniquely characteristic way, transmitting its own jagged spike signature to the monitor. Unfortunately, says Ross, that's the sort of thing even trained MDs aren't always comfortable with; they are used to -- and prefer -- looking at images. "It reminds them of the biochemistry courses that they came to hate in college or medical school." Partly for this "psychological" reason, but also because it requires more powerful magnets, MRS has been much slower to catch on than its younger sibling MRI, but Ross and others predict that situation will change. When it does, they say, the diagnosis and treatment of certain cancers and other diseases will be significantly advanced. MRS is available only at a few places, such as the Diasonics plant, the Veterans Administration Medical Center in San Francisco and Duke University, on an experimental basis to selected patients like Ross's M. (Huntington is installing a powerful new magnet, capable of producing a field of 1.5 tesla -- about 30,000 times the strength of the earth's magnetic field -- that will be shared by both Bradley's imaging team and Ross's spectroscopists.) But if Ross and his colleagues have their way, it will soon move out of the experimental stage and into medicine's mainstream. Dr. Michael C. Weiner, who runs the MRS lab at the VA hospital in San Francisco, is sure that day is rapidly approaching. "This technique allows us to 'see' how the cells are working," says the 48-year-old transplanted New Yorker, "without cutting or needles, without X-rays, without any harmful radiation. Just magnetism and radio waves." Even if it shuns scalpels, Weiner's lab has certainly been on the cutting edge. In close collaboration with the University of California San Francisco Medical Center, it is using MRS to unravel the chemistry of heart attacks, of brain and spinal injuries, even of muscle fatigue -- the later, surprisingly, still largely a mystery even after many years of research. In a cleverly designed series of experiments, healthy young men flexed their muscles in a specially built exerciser, while MRS scrutinized the metabolic chemistry of their exertions. As they exercised, the expected biochemical changes were documented: The store of the metabolite phosphocreatine in their muscles decreased; the synthesis of ATP, an energy-storing compound that fuels cellular activity, dropped off; the concentration of lactic acid rose; eventually the muscles no longer would contract. Such studies aren't merely helpful to would-be jocks, says UC San Francisco's Dr. Robert G. Miller. They may eventually aid those who suffer from such muscle-weakening diseases as multiple sclerosis, myasthenia gravis and amyotrophic lateral sclerosis (Lou Gehrig's disease). At last year's annual meeting of the Society of Magnetic Resonance in Medicine, held in San Francisco, dozens of doctors flocked to the basement lab to see for themselves the big magnet where these and other MRS experiments have been done. Of special interest to doctors is the metabolism of cancer cells. While chemotherapy and radiation have scored some major successes in controlling their rapid growth, oncologists work largely in the dark as they try to estimate what dosages and combinations of drugs and radiation will work. Huntington's Bradley sums up the situation: "We're still in the Stone Age when it comes to treating cancer. The metabolism of cancer cells fluctuates from day to day, yet we dose patients with drugs and radiation without any idea of what stage the cells are in at the particular moment of treatment." That could soon change because MRS can detect shifts in cellular metabolism almost as soon as they occur. In a recent experiment on himself, Dr. James W. Prichard at Yale University imbibed some Champagne, underwent a brain scan and almost immediately found a sharp ethanol (alcohol) spike. It represented the chemical changes induced in the cells of his brain by the bubbly. Similarly, West German doctors, using magnetic resonance spectroscopy, have been able to track chemical changes in the brain's visual center when the eyes open and when they close. By looking for chemicalk changes in response to physical stimuli, the techniques could be used to map other areas of the brain, an organ that still remains something of a mystery. In any case, the rapid detection of chemical changes may enable doctors to pick the precise moment that cancer cells are most receptive to chemotherapy. And almost immediately after the anti-cancer drugs are administered, MRS could be used to monitor their effectiveness against the target cells. No longer would doctors have to wait weeks or months to look for shrinkage or growth of a tumor. In fact, it was in quest of just such an assessment that Ross flew to San Francisco with his cancer-ridden patient. "The examination lets us detect a number of things that tell us something about the reaction of the tumor cells to the treatment," he explains. "We can, for example, detect the presence -- or absence -- of ATP. We can also pick up other metabolites . . . as well as inorganic phosphates and even pH, or cellular acidity." The relative amounts detected -- as measured by the size of the squiggles on the monitor of his machine -- are a precise indication of whether a cluster of cancer cells is growing or being held in check. "The key," says Ross, "is phosphocreatine because if its levels return to normal you know that the patient is most probably responding to the treatment." Phosphocreatine is a sensitive indicator of a depleted energy state. Successful treatment is also likely to be signaled by a rise in the level of inorganic phosphate since this is a breakdown product of dying cells. The biochemical intricacies of such measurements do not faze Ross, a specialist in metabolic diseases who studied biochemistry under Nobel laureate Sir Hans Krebs. His first clinical triumph with MRS came at Oxford in 1981. It involved a retired sailor plagued by continual fatigue. Ross suspected McArdle's syndrome, a rare genetic disease in which the muscles can't break down the sugar glycogen, used as a source of energy to fuel contraction. The disease could have been confirmed by biopsy or complex chemical tests. But he was determined to provide a diagnosis simply and noninva- sively. Using a magnet just big enough to enclose the patient's arm, he charted precisely the expected deficiencies in the man's muscle metabolism -- and dramatically confirmed his hunch. The man had the muscle- weakening syndrome. Ross's diagnostic feat was glowingly received. "The introduction of a new technique to the bedside always stimulates intellectual reverberations that go beyond the narrow range of the instrument," editorialized The New England Journal of Medicine. "Perhaps the most important contribution (of MRS) to clinical medicine will be that it will make us start thinking about familiar diseases in a new way." Bradley, who helped recruit Ross to Pasadena, calls spectroscopy a technique looking for an application. "We have hundreds of spectroscopists that would like to do their trade in a medical environment. Instead of high-falutin' laboratory science, they want to bring spectroscopy down to earth and do it in a worthwhile way that will help patients. Brian is trying to do that." It's now late in the day. Ross has finished his work with M at the factory site, and the men are heading back to San Francisco airport. "What did you learn, Doc?" M asks. Ross smiles. "I'd say that for now the news is good. The tumor hasn't grown." In a few weeks, doctor and patient will return to San Francisco for another session with the powerful magnet to see if the news is still good.
19901008000000000	WORK ON TRANSPLANTS NETS 2 AMERICANS A NOBEL. Two Americans -- one who performed the first successful kidney transplant and one who pioneered bone marrow transplants -- won the Nobel Prize in medicine today. Joseph E. Murray, 71, discovered how to master the problem of organ rejection and, in 1954, made the first successful organ transplant, a kidney from one identical twin to another that functioned for 24 years. The work of E. Donnall Thomas, 70, lessened the severe reaction that bone marrow transplants can cause in the recipients. His work led to a cure for leukemia in 50% of cases, and in 80% of childhood cases. "This year's laureates paved the way for transplantation in man," said the award citation from the Nobel Assembly of the Karolinska Institute. Bone marrow transplants are now used to treat a variety of cancers and inherited diseases, and researchers are investigating their potential use in AIDS and other diseases. The award citation said Murray "pioneered transplantation of kidneys obtained from deceased persons. . . . The field was then open for transplantation of other organs, such as liver, pancreas and heart." Murray, who is affiliated with Brigham and Women's Hospital in Boston, was in San Francisco for a medical conference when he heard he had won. "The thing about this that's marvelous is that Don and I both were in Brigham Hospital together," said Murray, a native of Milford, Mass. "He was a resident in medicine, and I was a resident in surgery. This was after World War II. We both started working in transplants together, but from different angles. It's marvelous to share it with him." Thomas said this morning from his home in Bellevue, Wash., that he had always thought his work was too clinical to win the prize. There have been 142 medicine prizes since the award was first given in 1901. Americans have dominated the prize, winning or sharing it 69 times.
19891010000000000	CANCER DISCOVERY EARNS NOBEL PRIZE FOR 2 AT UC. Two UC San Francisco scientists who unearthed "the seeds of cancer" buried deep in the genetic makeup of both humans and animals won the Nobel Prize in medicine Monday. Their discovery is widely credited with sparking a revolution in cancer research. Drs. J. Michael Bishop and Harold E. Varmus received the award for their finding in the mid-1970s that certain genes that guide normal growth can be converted into cancer-causing genes -- called oncogenes -- that transform healthy cells into tumor cells. "The first time I read the thesis, I thought I had misunderstood it," said Prof. Gosta Garthon of Sweden's Nobel awarding committee. "Imagine: The likely cause of cancer comes from us, and all that the outside factors have to do is to push the right button." Cancer researchers hailed the committee's choice as a powerful acknowledgement of the importance of research into oncogenes, about 40 of which have now been identified and linked to 20 forms of cancer, including cancers of the lung and breast. "The discovery of oncogenes was a great, seminal discovery that has determined the course of cancer research ever since," said Peter Vogt, a prominent USC microbiologist who collaborated with Bishop and Varmus. "I think cancer research has been completely transformed by this discovery." However, the announcement was marred Monday when a French researcher who worked with Bishop and Varmus complained bitterly that he should have shared in the award and that the Nobel committee ignored his contribution. Dr. Dominique Stehelin, now at the Pasteur Institute in Lille, told Agence France-Presse, "I did all the work by myself, from A to Z." He called his exclusion from the award "very unfair and rotten." In a press conference in San Francisco, Bishop described Stehelin as a post-doctoral fellow at the time "who carried out the bulk of the experiments." Varmus and others said the complex evolution of oncogene research has made it difficult to determine how to allocate credit for pioneering work. "All work that goes on in science was not done in a vacuum," said Dr. Stuart Aaronson, chief of the laboratory of cellular and molecular biology at the federal National Cancer Institute. "Their work built on critically important work done by many." Bishop, 53, and Varmus, 49, both professors of microbiology at UCSF, arrived at their discovery through research into so-called retroviruses, a group of viruses suspected of being the most prevalent viral cause of tumors. In the mid-1970s, the researchers found that a particular virus gene responsible for transforming a normal cell into a cancerous cell was actually derived from a normal gene present in chromosomes of all animals, including humans. That gene and others like it, called proto-oncogenes, can be converted into oncogenes by outside influences such as viral infections or exposure to carcinogens, including chemicals and radiation. Once converted, they then transform normal cells into cancerous cells. "The idea (had) been around for a long time that . . . cancer cells happen because something goes wrong with the genetic machinery that runs our cells," Bishop said Monday. "The idea is that something happens to those genes. They get damaged and cause cells to run amok.  Part of 'Genetic Dowry' "Our work gave substance to the idea that our cells contain genes that if damaged can give rise to cancerous growth," he added. "So, if you will, we have the seeds of cancer in our own genetic dowry." That discovery, published in 1976, opened up two areas for further research. Scientists began searching for other oncogenes capable of setting in motion other forms of cancer and they began examining the role of their precursors, or proto-oncogenes, in normal growth and development. "These genes control normal rates of growth and development of tissues and body parts," said Dr. Laurence Kedes, chairman of the department of biochemistry at USC School of Medicine. "That's the brilliant insight -- that these cancer genes are closely linked to normal cellular division and development." A gene is the basic unit of heredity. It is contained within the nucleus of a cell and influences its workings. Every human cell holds more than 50,000 genes which, all together, direct the development and functioning of all organs and systems in the body. Researchers said the oncogene findings may eventually produce new approaches to diagnosing and treating some cancers. The discovery that different cancers are caused by different, and very specific, genes suggests the need for a wide range of approaches, they said.  Question for the Future "Can we, by knowing what turns on oncogenes, figure out how to turn them off?" wondered Dr. John Laszlo, senior vice president for research at the American Cancer Society, who said researchers are exploring ways of "putting the brakes back on the oncogenes." Laszlo also suggested that understanding which oncogenes trigger which cancers might make it possible to screen people for particular susceptibilities, thus enabling public health authorities to better target education and prevention activities. It may also be possible to develop products that would counteract the effects of oncogenes on normal cells. The Nobel Prize is awarded by the 50-member Nobel Assembly of the Karolinska Institute in Sweden. Bishop and Varmus were chosen for the 1989 prize in medicine from about 250 scientists whose names were submitted by nominating organizations. It is not uncommon for Nobel Prizes to be awarded for work done many years earlier. Bishop and Varmus received word of the prize, which carries a $460,000 award, before dawn Monday. Varmus was awakened by a call from a radio reporter looking for a comment; Bishop, whose son woke him, described the experience as "surreal." They celebrated with a champagne press conference at UCSF at 8:30 a.m. -- early enough to get out in time to watch the San Francisco Giants play the Chicago Cubs at Candlestick Park in game five of the National League Championship Series. Asked whether they had received advice on what to do with the money, Varmus said his wife had suggested a built-in dishwasher. Born in York, Pa., Bishop is a graduate of Gettysburg College and Harvard Medical School. After two years of post-doctoral training at the federal National Institutes of Health, he joined the UCSF faculty in 1968. Varmus was born in Oceanside, N.Y., and holds a bachelor's degree from Amherst College, a master's from Harvard and a medical degree from Columbia University. He, too, worked briefly at the NIH and went to work at UCSF in 1970. Both men are married with two sons.
19891012000000000	4 AMERICANS, W. GERMAN SHARE NOBEL SCIENCE PRIZES. The Nobel Prize in physics was awarded today to two Americans and a West German whose work led to the atomic clock used as an international standard. The chemistry prize went to two Americans for the discovery of surprising properties of the genetic material RNA. The physics award was given to Norman F. Ramsey of Harvard University for measurement techniques that led to the cesium atomic clock, and to Hans G. Dehmelt of the University of Washington and Wolfgang Paul of the University of Bonn for a method to isolate single atoms and make exacting measurements of them.  Genetic Research The Nobel Prize in chemistry is shared by Thomas Cech, 41, of the University of Colorado, and Sidney Altman, 50, of Yale University. They showed independently in the 1970s and early 1980s that RNA, then thought to be merely a genetic messenger, could rearrange itself and produce chemical reactions. Their discovery "will probably provide a new tool for gene technology, with potential to create a new defense against viral infections," the Swedish Academy said. Half the physics prize will go to Ramsey, 74. The other half will be shared by Dehmelt, 67, and Paul, 76. "All three of them have developed exact methods of measurement, which has made it possible to conduct experiments that might force us to reconsider some basic physical laws, especially regarding time and space," said Ingvar Lindgren, chairman of the awarding committee.  Prize Worth $469,000 Each Nobel Prize is worth $469,000. Informed by the Associated Press that he had won the prize, Ramsey said: "Are you sure? It feels great. I'm just delighted, and I'm delighted with the people with whom I'm sharing the prize." Cech, reached in Boston, said: "My main emotion is that this is a great thing for the University of Colorado and the state of Colorado. This is not the sort of event that happens annually in the mountains the way it does in Boston. That gives me a really good feeling." The Canadian-born Altman, reached by telephone in New Haven, Conn., said, "I'm very happy. I'm very grateful to all my colleagues and co-workers, teachers and family." Americans have shared or won the chemistry prize 36 times among the 112 times it has been awarded since 1901. Fifty-two of the 134 recipients of the physics prize have been Americans. Last year's winners were Americans Leon Lederman, Melvin Schwartz and Jack Steinberger.
19891013000000000	4 AMERICANS, GERMAN SHARE SCIENCE NOBELS. Two American molecular biologists who revolutionized scientists' view of the nature of the first life on Earth won the Nobel Prize for chemistry on Thursday, while two Americans and a German physicist who developed new techniques for highly accurate timekeeping shared the physics Nobel. Thomas Cech of the University of Colorado in Boulder and Sidney Altman of Yale University will share the $460,000 chemistry prize for their unexpected discovery that ribonucleic acid (RNA), which was originally thought only to be a repository of genetic information, can carry out biochemical functions as well. The discovery may make possible new ways to fight the common cold and other viruses. Norman Ramsey of Harvard University will receive half the physics prize for his discovery of the atomic clock, which utilized the element cesium to make modern timekeeping possible and, in the process, helped develop a firm underpinning for relativity, one of the most esoteric theories in physics. Hans G. Dehmelt of the University of Washington in Seattle and Wolfgang Paul of the University of Bonn in West Germany shared the other half for their development of techniques for trapping charged particles for long periods of time, which is expected to lead to the development of clocks that are many times more accurate than even the cesium clocks. The announcements completed a near-sweep of the science Nobels by U.S. researchers this year, continuing U.S. dominance of the prizes. On Monday, cancer researchers Harold E. Varmus and J. Michael Bishop of UC San Francisco were named winners of the medicine Nobel, making six of the seven recipients Americans. All the new laureates expressed surprise and delight upon their early morning notification of the awards. "I would not say I expected it," Dehmelt said, "but I may have hoped or wished for it." "It was something that everyone has been telling me would happen," Cech said, "but I had no way of knowing when." At a morning celebratory party at Harvard, Ramsey poured champagne for two previous Harvard Nobel laureates and, before pouring his own glass, paused and said: "Well, my day is probably shot anyway." Asked about his plans for the prize money, Dehmelt said: "I will spend it." Cech, 41, and Altman, 50, helped evolutionary biologists attack an age-old puzzle that is often stated in terms of the riddle, "Which came first, the chicken or the egg?" In this case, the "egg" is deoxyribonucleic acid (DNA), the genetic blueprint that stores all the information from which organisms are constructed, while the "chickens" are proteins, which carry out all biochemical functions in the cell. Biologists reasoned that the first life on Earth had to have both genetic information and biochemical functions, implying that both DNA and proteins must have been present when the first life arose from the primordial ooze. But virtually everyone agrees that a system containing both DNA and proteins is too complex to have arisen spontaneously, leaving researchers at an impasse. Cech and Altman, working independently, solved the problem by focusing on RNA, which until that time had been considered only a simple messenger -- in effect, a set of working blueprints, copied from the master blueprint of DNA, that serve as a pattern for the construction of proteins. In 1978, the Canadian-born Altman was studying an RNA-cutting protein from a bacterium when he found that RNA fragments were necessary for the activity of the protein. Altman himself had difficulty believing his results and even greater difficulty publishing them. Funding agencies were also highly skeptical about his claims. But in 1981, Cech, who received his doctorate from UC Berkeley, demonstrated that the cutting and splicing of RNA from a single-celled protozoan could be carried out in the absence of proteins. He and Altman subsequently showed that RNA could take the place of proteins called enzymes in carrying out many chemical reactions, opening a floodgate of new research on RNA. But researchers also believe that the concept of RNA enzymes will have even greater importance in the future because they might be used to destroy viruses or to remove the genetic information that makes them harmful, leading to new treatments for disease. Although not as old as the origin of life, the problem of keeping time has plagued humans for eons. From the beginning of time until 1967, timekeeping methods were based on the rotation of the Earth. In that year, the world switched to a newer form of timekeeping based on the oscillations of cesium atoms in a so-called atomic clock. That clock was largely the work of Ramsey, 74. In essence, Ramsey found a way to measure the frequency with which cesium atoms, flying through a cavity, switch between two electronically excited states. Since 1967, one second has been defined internationally as the time required for 9,192,631,770 such oscillations. The chief advantage of the atomic clock is that it is accurate to one second in 300,000 years. Precise timekeeping is crucial in a variety of modern applications. In satellite-based navigation systems, for example, the time required for a radio signal to travel to a ship or plane from satellites can be used to determine position precisely, but only if the timekeeping is accurate. Deep space communications also require extremely stable frequencies such as those produced by atomic clocks. The new clocks have also been crucial in confirming Einstein's Theory of General Relativity, which predicts, among other things, that time passes faster when gravity is lower, but more slowly for objects traveling at high speed. But the differences are so small that high accuracy is required. In one experiment, for example, a cesium clock was carried in an airplane flying at 30,000 feet for 15 hours. When the plane landed, the clock had gained about 45 billionths of a second, confirming the theory. But the accuracy of atomic clocks is limited by the necessity of measuring the oscillations of the fast-moving cesium atoms, a problem akin to taking a clear photograph of a speeding bullet. The 57-year-old Dehmelt, a naturalized citizen born in Germany, and Paul, 76, devised techniques for trapping single cesium ions (atoms from which an electron has been stripped away) or other charged particles in magnetic fields for long periods of time. Using these techniques, researchers at the National Institute of Standards and Technology, the nation's official timekeeper, are now developing clocks that are 100,000 times as accurate as existing cesium clocks.
19901017000000000	THREE AMERICANS SHARE IN NOBEL SCIENCE PRIZES; AWARDS: THE DETECTION OF QUARKS AND A METHOD OF LAB ANALYSIS ARE HONORED IN PHYSICS AND CHEMISTRY.. Two American physicists and a Canadian who first detected the universe's tiniest known particles -- quarks -- and an American chemist who re-creates natural substances in the lab were honored today with 1990's final Nobel Prizes. Jerome I. Friedman and Henry W. Kendall of the Massachusetts Institute of Technology and Canadian Richard E. Taylor of Stanford University will share the $700,000 Nobel Prize in physics. "Their discoveries are a breakthrough in our understanding of the structure of matter," the Royal Swedish Academy of Science said in its award citation. "I'm totally overwhelmed, surprised and very honored -- all those types of things," Friedman, 60, said by telephone from Ft. Worth, where he was attending a symposium. "I never really thought of that as a real possibility." Kendall, 64, said in a telephone interview from Cambridge, Mass., that he was "overwhelmed" and had not expected to win. "Numb, I guess, is the closest word," said Taylor, 60, by telephone from his home on the Stanford campus near Palo Alto. "I certainly didn't expect it. It will probably hit me in a day or two." The $700,000 Nobel in chemistry went to Elias James Corey, 62, of Harvard University, for his work advancing the theory and methodology of organic synthesis. Corey in the 1960s developed "retrosynthetic analysis," a method of breaking down a natural molecule into its component parts to determine how it can be reassembled in the lab. "In this way, less complicated building blocks were obtained which could later be assembled in the process of synthesis," the academy said in its award citation. In particular, it said, Corey's achievement was to show how his method lent itself easily to computer programming, starting a process of computer synthetic planning that is "developing rapidly." The three physicists were cited for research more than 20 years ago that led to an explosion of understanding of the most fundamental nature of matter. Their work confirmed the existence of quarks, the building blocks used to form neutrons and protons. Those particles, in turn, make up the bulk of the atom, the building block of the molecule, the basis of all matter. Friedman, Kendall and Corey are the sixth, seventh and eighth Americans to win 1990 Nobel prizes. Taylor is the first Canadian to win the physics prize. The 1990 awards, now all announced, will be presented to the laureates on Dec. 10, the anniversary of the death of Alfred Nobel, the Swedish inventor of dynamite who created the prizes in his 1895 will.
19891026000000000	ALLAIS: "WALL STREET HAS BECOME A VERITABLE CASINO."; MARKETS: NOBEL LAUREATE MAURICE ALLAIS SAYS THE WEAKNESSES ON THE GLOBAL EXCHANGES ARE THE SAME AS THOSE THAT LED TO THE 1929 CRASH.. Loose credit practices, insufficient margin requirements and computerized trading on a nonstop world market have produced the volatile climate that now characterizes Wall Street, French economist Maurice Allais said in an interview with The Times. "Wall Street has become a veritable casino," said Allais, 78, a market theorist who won the 1988 Nobel Prize for economics. "In fact, the weaknesses of Wall Street today are the same as those that led to the crash of 1929. They are simply more marked." Allais, retired professor at the elite Ecole Nationale Superieure des Mines in Paris, is recognized as one of the leading researchers into the functioning of markets. "Allais is a fountain of original and independent discovery," American economist Paul Samuelson said of the French scholar at the time of the Nobel award. "Had his earlier writings been in English, a generation of economic theory would have taken a different course." Despite his influence on younger French economists, Allais has rarely been interviewed outside France. The questions in the following interview were posed by Los Angeles Times London bureau chief Dan Fisher. Allais' responses were translated from the French by Times Paris bureau chief Rone Tempest in consultation with the economist. Question: In view of the 190-point drop in the Dow on Friday, Oct. 13, and a sharp climb of 88 points on Monday, Oct. 16, do you think the Wall Street system has gone mad? Answer: I wouldn't say that Wall Street has gone mad. The reality is that the institutional framework in which Wall Street operates is fundamentally inappropriate, and it inevitably generates violent fluctuations of the market. What must necessarily happen, inevitably does. Q: Do you see this as reflecting some flaw in the American character? Or are the violent swings in the Dow Jones average just a price we have to pay for the world's increasingly interrelated financial markets? A: It is not a flaw particular to the American character. The European and Asian markets suffer from the same flaws. The interrelations between today's nonstop 24-hour financial markets are totally excessive and harmful. They are not at all necessary for the working of the world economy. I note, for example, that more than $400 billion is exchanged every day on the foreign exchange markets, while the flow of commercial transactions is only about $12 billion. Q: What do you see as the main weaknesses of the American markets? A: First, excessive financing of speculation by means of payment created ex nihilo by the mechanism of credit; second, insufficient margin requirements for all the futures speculators; third, the continuous trading market, which is an aberration from an economic viewpoint and generates a potentially permanent instability favoring fraud and manipulation of the market -- I think a single daily price quotation in each place for each stock would be by far preferable and would benefit both small and large investors, fourth, the automatic computerized buy and sell orders associated with continuous trading. Because of these four factors, Wall Street has become a veritable casino. In fact, the weaknesses of Wall Street today are the same as those which led to the crash of 1929. They are simply more marked. It is understandable that the Fed injects cash to avoid the collapse of the stock market, but basically it is bad policy for monetary authorities to intervene to save speculators from bankruptcy. This is not their role. Speculation would be useful if, and only if, these four major structural defects I mentioned are remedied. Today's system is anti-economic and basically unfavorable to the American system. It benefits only a very small minority. Q: What do you think about the whole takeover phenomenon? Junk bonds? A: Takeovers are fundamentally useful, but legislation concerning them should be reformed. It is undesirable that they should be financed by means of payment created out of nothing by the banking system, or by the issuing of junk bonds. In principle, junk bonds are basically useful, but they are used excessively and irrationally, notably in takeovers. Q: How do you think that the American system could be changed to correct its flaws? A: The American system could be reformed in the following ways: * Making it impossible to create means of payment ex nihilo by the credit mechanism. * Considerably increasing margin requirements on buying and selling. * Eliminating the continuous trading market and replacing it everywhere with a single daily trading price for each stock in each market. * Ending automatic, computerized buying and selling. Q: How is the French system, for example, different from the American one? What is the impact of Wall Street on the French system? Is it growing or lessening? A: The European criticisms of the American financial system could be addressed just as valuably to the European systems. The French system suffers from the same defects. They are simply less pronounced. Unfortunately, the French imitate the worst aspects of the American market, as in, for example, the continuous trading market. The impact is increasing. The effects are very bad: basically, the creation of a potentially permanent instability and the greater and greater disassociation of the financial system from the real economy.
19891222000000000	MIT RESEARCHERS IDENTIFY 'MASTER BUILDER' GENE; SCIENCE: THE GENE CONTROLS THE BODY'S DISEASE-FIGHTING PROCESS. THE DISCOVERY HAS NO IMMEDIATE MEDICAL APPLICATION, BUT COULD LEAD TO THE DEVELOPMENT OF DRUGS THAT WOULD FINE-TUNE THE IMMUNE SYSTEM.. Molecular biologists from the Massachusetts Institute of Technology report that they have isolated and identified the "master builder" gene that controls the disease-fighting process, marshaling its forces like a general preparing to repel an enemy invasion. The discovery, reported in today's Cell journal, should provide fundamental new insights into how the immune system functions, according to pathologist Michael Lieber of Stanford University. "I would think it would be one of the top 10 . . . discoveries in immunology," Lieber said. "It is a remarkable technical achievement, an extremely elegant piece of science," added molecular immunologist Frederick Alt of Columbia University in New York City. "We now have in hand the tools to dissect the system that is involved in the assembly of antibody genes. We'll make a tremendous amount of progress in the next year." The discovery of how this process is controlled has no immediate medical application, but the finding could eventually lead to the development of drugs that would fine-tune the immune system. Even further off, it might lead to ways to repair the ravages of the immune system caused by the AIDS virus. Over a lifetime, a human encounters literally tens of thousands of different infectious bacteria, viruses, fungi and parasites. Most of the time, these encounters are benign because humans have evolved a remarkable immune mechanism that, at any given time, posts more than 100,000 unique sentries to identify the invaders and sound the warning call for their destruction. Surprisingly, the body's genetic repertoire does not have a set of genes that serve as blueprints for each of these sentries, called B cells. Instead, it has a small library of DNA (deoxyribonucleic acid) fragments that are constantly being chopped up, shuffled and recombined to produce millions of different B cells over the course of a lifetime. Defects in the gene may be responsible for some of the genetic diseases that produce a non-functioning immune system, such as that suffered by David, the "bubble boy" in Houston who spent all of his short life in a plastic-enclosed, sterile environment. Defects might also lead to the formation of tumors of the immune system. Some biologists believe that a similar shuffling and recombining process may play a role in the differentiation of unspecialized cells in the early embryo into specialized cells in various organs, particularly in the brain and nervous and sensory systems. The gene that has been identified could be used as a probe to locate such genes in other systems. Biologists have long puzzled over the riddle of how the body could generate the large number of individual antibody-secreting cells that are known to exist in the immune system. Immunologist Susumu Tonegawa of Japan solved that in the early 1980s by demonstrating that a small genetic library could be constantly reshuffled and recombined to produce the necessary number of antibodies -- a feat for which he won the 1989 Nobel Prize for Medicine. "Since then, we have learned surprisingly little" about how the body achieves this rearrangement, said molecular biologist David Baltimore of MIT's Whitehead Institute for Biomedical Research, the leader of the team that isolated the gene. "This is the first step toward finding a chemical basis of diversity." Baltimore and two graduate students, David G. Schatz and Marjorie A. Oettinger, isolated the gene from human white blood cells. They were able to prove the gene's function by inserting it into cultured skin cells, which -- like all cells in the body other than immune cells -- cannot normally carry out the shuffling and recombination process. After the gene was inserted, the skin cells were able to do so, Oettinger said in a telephone interview. The researchers still do not know precisely how the gene functions, however. In fact, there are two possibilities. One is that the gene codes for an enzyme called recombinase. That enzyme, Lieber said, is a "molecular surgeon" that actually carries out the cutting and recombining process. Alternatively, the gene could operate at the genetic level, orchestrating the entire recombination process by turning on and off the genes for recombinase and other components of the system. For a variety of reasons, the MIT group believes that the gene is the blueprint for the recombinase, Oettinger said. But either way, she said, "It is going to teach us a lot more about the basic science of the immune system."
10000000000000000	Nobel Prize Winners in the Sciences and Economics Nobel prizes are awarded each year for achievements in the sciences  physics  chemistry  physiology and medicine  and economics   Who are the Nobel prize winners in the sciences and in economics and are their prize winning achievements  What are common factors in their backgrounds.
